{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.004414,
     "end_time": "2025-05-27T13:18:36.102497",
     "exception": false,
     "start_time": "2025-05-27T13:18:36.098083",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This notebook will show you how to use the \"Gemini 2.5 Flash\" language model in Kaggle using an open API at the Python code level. Gemini is a group of powerful large language models known for their high performance in coding and reasoning tasks released by Google. Version 2.5 Flash is one of the most popular and enjoys high rankings in many benchmarks.\n",
    "\n",
    "Let's dive in and discover the possibilities of this exciting model. Today we will discover its multimodality - the input to the model will be both image and text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2025-05-28T15:56:13.030891Z",
     "iopub.status.busy": "2025-05-28T15:56:13.030558Z",
     "iopub.status.idle": "2025-05-28T15:56:18.943397Z",
     "shell.execute_reply": "2025-05-28T15:56:18.941818Z",
     "shell.execute_reply.started": "2025-05-28T15:56:13.030863Z"
    },
    "papermill": {
     "duration": 6.349035,
     "end_time": "2025-05-27T13:18:42.455371",
     "exception": false,
     "start_time": "2025-05-27T13:18:36.106336",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade --quiet google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T15:56:18.946695Z",
     "iopub.status.busy": "2025-05-28T15:56:18.946399Z",
     "iopub.status.idle": "2025-05-28T15:56:18.962713Z",
     "shell.execute_reply": "2025-05-28T15:56:18.961606Z",
     "shell.execute_reply.started": "2025-05-28T15:56:18.946667Z"
    },
    "papermill": {
     "duration": 0.022199,
     "end_time": "2025-05-27T13:18:42.481569",
     "exception": false,
     "start_time": "2025-05-27T13:18:42.459370",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from IPython.display import HTML, Image, Markdown, display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.003699,
     "end_time": "2025-05-27T13:18:42.489473",
     "exception": false,
     "start_time": "2025-05-27T13:18:42.485774",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We will start by installing and loading the necessary packages. The base here will be the google.genai package, which allows you to talk to this model and all the necessary functions needed to explore it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T15:56:18.964118Z",
     "iopub.status.busy": "2025-05-28T15:56:18.963804Z",
     "iopub.status.idle": "2025-05-28T15:56:20.617038Z",
     "shell.execute_reply": "2025-05-28T15:56:20.616276Z",
     "shell.execute_reply.started": "2025-05-28T15:56:18.964058Z"
    },
    "papermill": {
     "duration": 1.526264,
     "end_time": "2025-05-27T13:18:44.019585",
     "exception": false,
     "start_time": "2025-05-27T13:18:42.493321",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import re\n",
    "from typing import Dict, List, Any, Set\n",
    "import PIL.Image\n",
    "from pydantic import BaseModel, ValidationError\n",
    "\n",
    "# Updated imports for the new google.genai library\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "from google.genai.types import (\n",
    "    GenerateContentConfig,\n",
    "    Part,\n",
    "    SafetySetting,\n",
    "    HarmCategory,\n",
    "    HarmBlockThreshold,\n",
    "    ThinkingConfig\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import base64\n",
    "import re\n",
    "import logging\n",
    "import asyncio\n",
    "from typing import Dict, List, Any, Optional, TypedDict, Annotated, Union, Set, Tuple\n",
    "from enum import Enum\n",
    "from dataclasses import dataclass\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Gemini imports\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "from google.genai.types import (\n",
    "    GenerateContentConfig,\n",
    "    Part,\n",
    "    SafetySetting,\n",
    "    HarmCategory,\n",
    "    HarmBlockThreshold,\n",
    "    ThinkingConfig\n",
    ")\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T15:56:20.618418Z",
     "iopub.status.busy": "2025-05-28T15:56:20.617937Z",
     "iopub.status.idle": "2025-05-28T15:56:20.694704Z",
     "shell.execute_reply": "2025-05-28T15:56:20.693901Z",
     "shell.execute_reply.started": "2025-05-28T15:56:20.618388Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "os.environ[\"GOOGLE_API_KEY\"] = 'add_api_key'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T15:56:20.758790Z",
     "iopub.status.busy": "2025-05-28T15:56:20.758526Z",
     "iopub.status.idle": "2025-05-28T15:56:20.762870Z",
     "shell.execute_reply": "2025-05-28T15:56:20.761974Z",
     "shell.execute_reply.started": "2025-05-28T15:56:20.758761Z"
    },
    "papermill": {
     "duration": 0.011036,
     "end_time": "2025-05-27T13:18:44.156827",
     "exception": false,
     "start_time": "2025-05-27T13:18:44.145791",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "MODEL_ID = \"gemini-2.5-pro-preview-06-05\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.003685,
     "end_time": "2025-05-27T13:18:44.164795",
     "exception": false,
     "start_time": "2025-05-27T13:18:44.161110",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The last thing we need to configure is to fill in the model ID. Currently the latest version of APS April 17 official name is as in cell below. All model names can be checked in the model card on Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T15:56:20.765015Z",
     "iopub.status.busy": "2025-05-28T15:56:20.764761Z",
     "iopub.status.idle": "2025-05-28T15:56:23.120179Z",
     "shell.execute_reply": "2025-05-28T15:56:23.119284Z",
     "shell.execute_reply.started": "2025-05-28T15:56:20.764994Z"
    },
    "papermill": {
     "duration": 2.2993,
     "end_time": "2025-05-27T13:18:46.467898",
     "exception": false,
     "start_time": "2025-05-27T13:18:44.168598",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "def load_public_data():\n",
    "    with open('///mnt/c/Personal/Competitions/ICML_Track2/input/starting_kit_latest/total.json', 'r') as file:\n",
    "        data = json.load(file)\n",
    "    data = pd.DataFrame(data)\n",
    "    problems = data.to_dict('records')\n",
    "    return problems\n",
    "problems = load_public_data()\n",
    "# problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "from typing import Dict, List, Any, Set, Optional, Tuple\n",
    "from dataclasses import dataclass\n",
    "from pydantic import BaseModel\n",
    "import pandas as pd\n",
    "\n",
    "# Embedding and similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "\n",
    "# Existing imports for your pipeline\n",
    "import PIL.Image\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "from google.genai.types import (\n",
    "    GenerateContentConfig,\n",
    "    Part,\n",
    "    SafetySetting,\n",
    "    HarmCategory,\n",
    "    HarmBlockThreshold,\n",
    "    ThinkingConfig\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Physics Domain Definitions (same as OpenAI pipeline)\n",
    "PHYSICS_SUBJECTS = {\n",
    "    'O': 'Optics (Basic)',\n",
    "    'OPT': 'Optics (Extended/Advanced)', \n",
    "    'EM': 'Electromagnetism',\n",
    "    'CM': 'Classical Mechanics',\n",
    "    'TSM': 'Thermodynamics & Statistical Mechanics',\n",
    "    'QMIT': 'Quantum Mechanics & Information Theory',\n",
    "    'ACG': 'Astrophysics, Cosmology & Gravitation',\n",
    "    'AMONP': 'Atomic, Molecular, Optical & Nuclear Physics'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "PHYSICS_CATEGORIES = {\n",
    "    'MECHANICS': [\n",
    "        'static_force_analysis', 'spring_force', 'circular_motion', \n",
    "        'linear_motion', 'coordinate_system', 'simple_harmonic_motion', \n",
    "        'projectile_motion'\n",
    "    ],\n",
    "    'ELECTROMAGNETISM': [\n",
    "        'circuit_diagram', 'charge_distribution', 'magnetic_circuit', \n",
    "        'electromagnetic_field', 'capacitance_resistance'\n",
    "    ],\n",
    "    'WAVES_OPTICS': [\n",
    "        'optical_path', 'wave_motion', 'photoelectric_effect', 'acoustics'\n",
    "    ],\n",
    "    'THERMAL': ['thermodynamics'],\n",
    "    'MODERN': [\n",
    "        'atomic_physics', 'quantum_mechanics', 'relativity_gravity', \n",
    "        'feynman_diagram', 'astrophysics'\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "CATEGORY_EXPERTISE = {\n",
    "    'static_force_analysis': {\n",
    "        'en': 'Force equilibrium, vector analysis, torque calculations, structural mechanics, friction, constraint forces',\n",
    "        'zh': 'åŠ›å¹³è¡¡ï¼ŒçŸ¢é‡åˆ†æï¼ŒåŠ›çŸ©è®¡ç®—ï¼Œç»“æ„åŠ›å­¦ï¼Œæ‘©æ“¦åŠ›ï¼Œçº¦æŸåŠ›'\n",
    "    },\n",
    "    'spring_force': {\n",
    "        'en': 'Hooke\\'s law, elastic energy, harmonic oscillations, coupled systems, resonance',\n",
    "        'zh': 'èƒ¡å…‹å®šå¾‹ï¼Œå¼¹æ€§èƒ½ï¼Œè°æŒ¯è¡ï¼Œè€¦åˆç³»ç»Ÿï¼Œå…±æŒ¯'\n",
    "    },\n",
    "    'circular_motion': {\n",
    "        'en': 'Centripetal force, angular momentum, rotational dynamics, orbital mechanics',\n",
    "        'zh': 'å‘å¿ƒåŠ›ï¼Œè§’åŠ¨é‡ï¼Œè½¬åŠ¨åŠ¨åŠ›å­¦ï¼Œè½¨é“åŠ›å­¦'\n",
    "    },\n",
    "    'linear_motion': {\n",
    "        'en': 'Kinematics, dynamics, momentum conservation, collision analysis',\n",
    "        'zh': 'è¿åŠ¨å­¦ï¼ŒåŠ¨åŠ›å­¦ï¼ŒåŠ¨é‡å®ˆæ’ï¼Œç¢°æ’åˆ†æ'\n",
    "    },\n",
    "    'coordinate_system': {\n",
    "        'en': 'Graph analysis, data interpretation, coordinate transformations, vector fields',\n",
    "        'zh': 'å›¾å½¢åˆ†æï¼Œæ•°æ®è§£é‡Šï¼Œåæ ‡å˜æ¢ï¼ŒçŸ¢é‡åœº'\n",
    "    },\n",
    "    'simple_harmonic_motion': {\n",
    "        'en': 'Oscillation equations, period analysis, energy methods, damping effects',\n",
    "        'zh': 'æŒ¯åŠ¨æ–¹ç¨‹ï¼Œå‘¨æœŸåˆ†æï¼Œèƒ½é‡æ–¹æ³•ï¼Œé˜»å°¼æ•ˆåº”'\n",
    "    },\n",
    "    'projectile_motion': {\n",
    "        'en': 'Parabolic trajectories, range calculations, angle optimization, air resistance',\n",
    "        'zh': 'æŠ›ç‰©è½¨è¿¹ï¼Œå°„ç¨‹è®¡ç®—ï¼Œè§’åº¦ä¼˜åŒ–ï¼Œç©ºæ°”é˜»åŠ›'\n",
    "    },\n",
    "    'circuit_diagram': {\n",
    "        'en': 'Ohm\\'s law, Kirchhoff\\'s laws, impedance analysis, AC/DC circuits, network analysis',\n",
    "        'zh': 'æ¬§å§†å®šå¾‹ï¼ŒåŸºå°”éœå¤«å®šå¾‹ï¼Œé˜»æŠ—åˆ†æï¼Œäº¤ç›´æµç”µè·¯ï¼Œç½‘ç»œåˆ†æ'\n",
    "    },\n",
    "    'charge_distribution': {\n",
    "        'en': 'Electric fields, Gauss\\'s law, potential calculations, boundary conditions',\n",
    "        'zh': 'ç”µåœºï¼Œé«˜æ–¯å®šå¾‹ï¼Œç”µåŠ¿è®¡ç®—ï¼Œè¾¹ç•Œæ¡ä»¶'\n",
    "    },\n",
    "    'magnetic_circuit': {\n",
    "        'en': 'Magnetic flux, inductance, transformer principles, magnetic coupling',\n",
    "        'zh': 'ç£é€šé‡ï¼Œç”µæ„Ÿï¼Œå˜å‹å™¨åŸç†ï¼Œç£è€¦åˆ'\n",
    "    },\n",
    "    'electromagnetic_field': {\n",
    "        'en': 'Maxwell equations, wave propagation, Lorentz force, field interactions',\n",
    "        'zh': 'éº¦å…‹æ–¯éŸ¦æ–¹ç¨‹ï¼Œæ³¢ä¼ æ’­ï¼Œæ´›ä¼¦å…¹åŠ›ï¼Œåœºç›¸äº’ä½œç”¨'\n",
    "    },\n",
    "    'capacitance_resistance': {\n",
    "        'en': 'Dielectric properties, resistance networks, Hall effect, field distributions',\n",
    "        'zh': 'ä»‹ç”µæ€§è´¨ï¼Œç”µé˜»ç½‘ç»œï¼Œéœå°”æ•ˆåº”ï¼Œåœºåˆ†å¸ƒ'\n",
    "    },\n",
    "    'optical_path': {\n",
    "        'en': 'Ray tracing, lens systems, interference, diffraction, polarization',\n",
    "        'zh': 'å…‰çº¿è¿½è¿¹ï¼Œé€é•œç³»ç»Ÿï¼Œå¹²æ¶‰ï¼Œè¡å°„ï¼ŒåæŒ¯'\n",
    "    },\n",
    "    'wave_motion': {\n",
    "        'en': 'Wave equations, superposition, standing waves, Doppler effect',\n",
    "        'zh': 'æ³¢åŠ¨æ–¹ç¨‹ï¼Œå åŠ åŸç†ï¼Œé©»æ³¢ï¼Œå¤šæ™®å‹’æ•ˆåº”'\n",
    "    },\n",
    "    'photoelectric_effect': {\n",
    "        'en': 'Einstein equation, photon energy, quantum nature of light, work function',\n",
    "        'zh': 'çˆ±å› æ–¯å¦æ–¹ç¨‹ï¼Œå…‰å­èƒ½é‡ï¼Œå…‰çš„é‡å­æ€§ï¼ŒåŠŸå‡½æ•°'\n",
    "    },\n",
    "    'acoustics': {\n",
    "        'en': 'Sound propagation, acoustic resonance, sound intensity, echo analysis',\n",
    "        'zh': 'å£°ä¼ æ’­ï¼Œå£°å…±æŒ¯ï¼Œå£°å¼ºï¼Œå›å£°åˆ†æ'\n",
    "    },\n",
    "    'thermodynamics': {\n",
    "        'en': 'Laws of thermodynamics, heat transfer, phase transitions, statistical mechanics',\n",
    "        'zh': 'çƒ­åŠ›å­¦å®šå¾‹ï¼Œä¼ çƒ­ï¼Œç›¸å˜ï¼Œç»Ÿè®¡åŠ›å­¦'\n",
    "    },\n",
    "    'atomic_physics': {\n",
    "        'en': 'Nuclear structure, radioactive decay, particle interactions, cross-sections',\n",
    "        'zh': 'æ ¸ç»“æ„ï¼Œæ”¾å°„æ€§è¡°å˜ï¼Œç²’å­ç›¸äº’ä½œç”¨ï¼Œæˆªé¢'\n",
    "    },\n",
    "    'quantum_mechanics': {\n",
    "        'en': 'SchrÃ¶dinger equation, wave functions, quantum states, uncertainty principle',\n",
    "        'zh': 'è–›å®šè°”æ–¹ç¨‹ï¼Œæ³¢å‡½æ•°ï¼Œé‡å­æ€ï¼Œä¸ç¡®å®šæ€§åŸç†'\n",
    "    },\n",
    "    'relativity_gravity': {\n",
    "        'en': 'Special/general relativity, spacetime, gravitational effects, reference frames',\n",
    "        'zh': 'ç‹­ä¹‰/å¹¿ä¹‰ç›¸å¯¹è®ºï¼Œæ—¶ç©ºï¼Œå¼•åŠ›æ•ˆåº”ï¼Œå‚è€ƒç³»'\n",
    "    },\n",
    "    'feynman_diagram': {\n",
    "        'en': 'Particle interactions, conservation laws, quantum field theory, decay processes',\n",
    "        'zh': 'ç²’å­ç›¸äº’ä½œç”¨ï¼Œå®ˆæ’å®šå¾‹ï¼Œé‡å­åœºè®ºï¼Œè¡°å˜è¿‡ç¨‹'\n",
    "    },\n",
    "    'astrophysics': {\n",
    "        'en': 'Stellar physics, cosmology, orbital mechanics, astronomical observations',\n",
    "        'zh': 'æ’æ˜Ÿç‰©ç†ï¼Œå®‡å®™å­¦ï¼Œè½¨é“åŠ›å­¦ï¼Œå¤©æ–‡è§‚æµ‹'\n",
    "    }\n",
    "}\n",
    "\n",
    "SUBJECT_GUIDANCE = {\n",
    "    'O': {\n",
    "        'en': 'Focus on basic geometric optics, ray tracing, and fundamental optical phenomena',\n",
    "        'zh': 'ä¸“æ³¨äºåŸºç¡€å‡ ä½•å…‰å­¦ã€å…‰çº¿è¿½è¸ªå’ŒåŸºæœ¬å…‰å­¦ç°è±¡'\n",
    "    },\n",
    "    'OPT': {\n",
    "        'en': 'Apply advanced optics: wave optics, interference, diffraction, quantum optics',\n",
    "        'zh': 'åº”ç”¨é«˜çº§å…‰å­¦ï¼šæ³¢åŠ¨å…‰å­¦ã€å¹²æ¶‰ã€è¡å°„ã€é‡å­å…‰å­¦'\n",
    "    },\n",
    "    'EM': {\n",
    "        'en': 'Emphasize electromagnetic fields, circuits, Maxwell equations, wave propagation',\n",
    "        'zh': 'å¼ºè°ƒç”µç£åœºã€ç”µè·¯ã€éº¦å…‹æ–¯éŸ¦æ–¹ç¨‹ã€æ³¢ä¼ æ’­'\n",
    "    },\n",
    "    'CM': {\n",
    "        'en': 'Focus on classical mechanics: forces, motion, energy, momentum conservation',\n",
    "        'zh': 'ä¸“æ³¨äºç»å…¸åŠ›å­¦ï¼šåŠ›ã€è¿åŠ¨ã€èƒ½é‡ã€åŠ¨é‡å®ˆæ’'\n",
    "    },\n",
    "    'TSM': {\n",
    "        'en': 'Apply thermodynamic laws, statistical mechanics, heat transfer principles',\n",
    "        'zh': 'åº”ç”¨çƒ­åŠ›å­¦å®šå¾‹ã€ç»Ÿè®¡åŠ›å­¦ã€ä¼ çƒ­åŸç†'\n",
    "    },\n",
    "    'QMIT': {\n",
    "        'en': 'Use quantum mechanics, wave-particle duality, quantum information theory',\n",
    "        'zh': 'ä½¿ç”¨é‡å­åŠ›å­¦ã€æ³¢ç²’äºŒè±¡æ€§ã€é‡å­ä¿¡æ¯ç†è®º'\n",
    "    },\n",
    "    'ACG': {\n",
    "        'en': 'Apply gravitational physics, cosmology, relativity, astronomical principles',\n",
    "        'zh': 'åº”ç”¨å¼•åŠ›ç‰©ç†ã€å®‡å®™å­¦ã€ç›¸å¯¹è®ºã€å¤©æ–‡å­¦åŸç†'\n",
    "    },\n",
    "    'AMONP': {\n",
    "        'en': 'Focus on atomic structure, nuclear physics, particle interactions',\n",
    "        'zh': 'ä¸“æ³¨äºåŸå­ç»“æ„ã€æ ¸ç‰©ç†ã€ç²’å­ç›¸äº’ä½œç”¨'\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvaluationDecision(str, Enum):\n",
    "    ACCEPT = \"accept\"\n",
    "    REJECT = \"reject\"\n",
    "\n",
    "class PhysicsErrorType(str, Enum):\n",
    "    PHYSICS_THEOREM = \"physics_theorem_error\"\n",
    "    CONDITION_ANALYSIS = \"condition_analysis_error\"\n",
    "    PROCESS_UNDERSTANDING = \"process_understanding_error\"\n",
    "    CALCULATION = \"calculation_error\"\n",
    "    VARIABLE_RELATIONSHIP = \"variable_relationship_error\"\n",
    "    DIAGRAM_ANALYSIS = \"diagram_analysis_error\"\n",
    "    BOUNDARY_CONDITIONS = \"boundary_conditions_error\"\n",
    "\n",
    "class PhysicsErrorAnalysis(BaseModel):\n",
    "    physics_theorem_errors: List[str] = Field(default_factory=list, description=\"Wrong physics laws/formulas applied\")\n",
    "    condition_analysis_errors: List[str] = Field(default_factory=list, description=\"Misidentified forces, boundaries, setup\")\n",
    "    process_understanding_errors: List[str] = Field(default_factory=list, description=\"Misunderstood physical phenomena\")\n",
    "    calculation_errors: List[str] = Field(default_factory=list, description=\"Mathematical derivation errors\")\n",
    "    variable_relationship_errors: List[str] = Field(default_factory=list, description=\"Wrong dependencies between quantities\")\n",
    "    diagram_analysis_errors: List[str] = Field(default_factory=list, description=\"Misread visual information\")\n",
    "    boundary_conditions_errors: List[str] = Field(default_factory=list, description=\"Ignored constraints/limits\")\n",
    "\n",
    "class EvaluationResult(BaseModel):\n",
    "    decision: EvaluationDecision\n",
    "    confidence_score: float = Field(ge=0, le=1)\n",
    "    quality_score: float = Field(ge=0, le=1)\n",
    "    physics_errors: PhysicsErrorAnalysis\n",
    "    answer_consistency: bool\n",
    "    magnitude_reasonable: bool\n",
    "    error_location: Optional[str] = None\n",
    "    feedback_message: str\n",
    "    improvement_suggestions: Optional[str] = None\n",
    "\n",
    "class SolutionState(TypedDict):\n",
    "    problem: Dict[str, Any]\n",
    "    current_solution: Optional[str]\n",
    "    evaluation_result: Optional[EvaluationResult]\n",
    "    final_solution: Optional[str]\n",
    "    iteration_count: int\n",
    "    max_iterations: int\n",
    "    generation_history: List[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep the exact same LabeledExampleManager from OpenAI pipeline\n",
    "class LabeledExampleManager:\n",
    "    \"\"\"Manages labeled examples for few-shot enhancement\"\"\"\n",
    "    \n",
    "    def __init__(self, labeled_samples_path: str, logger: Optional[logging.Logger] = None):\n",
    "        self.samples = []\n",
    "        self.subject_category_index = {}\n",
    "        self.subject_index = {}\n",
    "        self.category_index = {}\n",
    "        self.logger = logger or logging.getLogger(__name__)\n",
    "        \n",
    "        if labeled_samples_path and os.path.exists(labeled_samples_path):\n",
    "            self._load_samples(labeled_samples_path)\n",
    "            self._build_indices()\n",
    "    \n",
    "    def _load_samples(self, file_path: str):\n",
    "        \"\"\"Load labeled samples from JSON file\"\"\"\n",
    "        try:\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                self.samples = json.load(f)\n",
    "            self.logger.info(f\"âœ… Loaded {len(self.samples)} labeled examples\")\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"âš ï¸ Failed to load labeled samples: {e}\")\n",
    "            self.samples = []\n",
    "    \n",
    "    def _build_indices(self):\n",
    "        \"\"\"Build indices for fast lookup\"\"\"\n",
    "        for sample in self.samples:\n",
    "            subject = sample.get('subject', '')\n",
    "            category = sample.get('img_category', '')\n",
    "            \n",
    "            # Subject + Category index\n",
    "            key = f\"{subject}_{category}\"\n",
    "            if key not in self.subject_category_index:\n",
    "                self.subject_category_index[key] = []\n",
    "            self.subject_category_index[key].append(sample)\n",
    "            \n",
    "            # Subject-only index\n",
    "            if subject not in self.subject_index:\n",
    "                self.subject_index[subject] = []\n",
    "            self.subject_index[subject].append(sample)\n",
    "            \n",
    "            # Category-only index\n",
    "            if category not in self.category_index:\n",
    "                self.category_index[category] = []\n",
    "            self.category_index[category].append(sample)\n",
    "    \n",
    "    def _calculate_quality_score(self, sample: Dict[str, Any], target_problem: Dict[str, Any]) -> float:\n",
    "        \"\"\"Calculate quality score for a sample\"\"\"\n",
    "        score = 0.0\n",
    "        \n",
    "        # Reasoning length/completeness (longer reasoning usually better)\n",
    "        reasoning = sample.get('reasoning', '')\n",
    "        if len(reasoning) > 100:\n",
    "            score += 0.3\n",
    "        elif len(reasoning) > 50:\n",
    "            score += 0.2\n",
    "        elif len(reasoning) > 20:\n",
    "            score += 0.1\n",
    "        \n",
    "        # Level preference (prefer same or slightly higher level)\n",
    "        sample_level = sample.get('level', 1)\n",
    "        target_level = target_problem.get('level', 1)\n",
    "        level_diff = abs(sample_level - target_level)\n",
    "        if level_diff == 0:\n",
    "            score += 0.3\n",
    "        elif level_diff <= 1:\n",
    "            score += 0.2\n",
    "        elif level_diff <= 2:\n",
    "            score += 0.1\n",
    "        \n",
    "        # Vision relevance match\n",
    "        sample_vision = sample.get('vision_relevance', '')\n",
    "        target_vision = target_problem.get('vision_relevance', '')\n",
    "        if sample_vision == target_vision:\n",
    "            score += 0.2\n",
    "        elif sample_vision in ['necessary', 'helpful'] and target_vision in ['necessary', 'helpful']:\n",
    "            score += 0.1\n",
    "        \n",
    "        # Language match\n",
    "        if sample.get('language', '') == target_problem.get('language', ''):\n",
    "            score += 0.1\n",
    "        \n",
    "        return score\n",
    "    \n",
    "    def find_best_examples(self, problem: Dict[str, Any], max_examples: int = 3) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Find best examples based on subject and category matching\"\"\"\n",
    "        if not self.samples:\n",
    "            return []\n",
    "        \n",
    "        subject = problem.get('subject', '')\n",
    "        category = problem.get('img_category', '')\n",
    "        \n",
    "        candidates = []\n",
    "        \n",
    "        # Priority 1: Exact subject + category match\n",
    "        exact_key = f\"{subject}_{category}\"\n",
    "        if exact_key in self.subject_category_index:\n",
    "            candidates.extend(self.subject_category_index[exact_key])\n",
    "            match_type = \"exact\"\n",
    "        \n",
    "        # Priority 2: Subject match only\n",
    "        elif subject in self.subject_index:\n",
    "            candidates.extend(self.subject_index[subject])\n",
    "            match_type = \"subject\"\n",
    "        \n",
    "        # Priority 3: Category match only  \n",
    "        elif category in self.category_index:\n",
    "            candidates.extend(self.category_index[category])\n",
    "            match_type = \"category\"\n",
    "        \n",
    "        # No matches - skip examples\n",
    "        else:\n",
    "            self.logger.debug(f\"ğŸ” No examples found for subject='{subject}', category='{category}'\")\n",
    "            return []\n",
    "        \n",
    "        # Calculate quality scores and sort\n",
    "        scored_candidates = []\n",
    "        for candidate in candidates:\n",
    "            score = self._calculate_quality_score(candidate, problem)\n",
    "            scored_candidates.append((score, candidate))\n",
    "        \n",
    "        # Sort by score (descending) and take top examples\n",
    "        scored_candidates.sort(key=lambda x: x[0], reverse=True)\n",
    "        selected = [candidate for score, candidate in scored_candidates[:max_examples]]\n",
    "        \n",
    "        self.logger.debug(f\"ğŸ¯ Found {len(selected)} examples ({match_type} match) for {subject}/{category}\")\n",
    "        \n",
    "        return selected\n",
    "    \n",
    "    def format_examples_for_prompt(self, examples: List[Dict[str, Any]], language: str = \"English\") -> str:\n",
    "        \"\"\"Format examples for inclusion in generation prompt\"\"\"\n",
    "        if not examples:\n",
    "            return \"\"\n",
    "        \n",
    "        lang_code = \"zh\" if language == \"Chinese\" else \"en\"\n",
    "        \n",
    "        if lang_code == \"zh\":\n",
    "            examples_text = \"\\n**ä¸“å®¶è§£é¢˜ç¤ºä¾‹ï¼š**\\n\\n\"\n",
    "            examples_text += \"ä»¥ä¸‹æ˜¯ç±»ä¼¼é—®é¢˜çš„ä¸“å®¶è§£é¢˜è¿‡ç¨‹ï¼Œè¯·å‚è€ƒå…¶æ¨ç†æ–¹æ³•å’Œè§£ç­”æ¨¡å¼ï¼š\\n\\n\"\n",
    "        else:\n",
    "            examples_text = \"\\n**EXPERT SOLUTION EXAMPLES:**\\n\\n\"\n",
    "            examples_text += \"Here are expert solutions to similar problems. Use these as guides for reasoning patterns and solution approaches:\\n\\n\"\n",
    "        \n",
    "        for i, example in enumerate(examples, 1):\n",
    "            question = example.get('question', '')\n",
    "            reasoning = example.get('reasoning', '')\n",
    "            answer = example.get('answer', '')\n",
    "            subject = example.get('subject', '')\n",
    "            category = example.get('img_category', '')\n",
    "            \n",
    "            if lang_code == \"zh\":\n",
    "                examples_text += f\"**ç¤ºä¾‹ {i}** [{subject}/{category}]:\\n\"\n",
    "                examples_text += f\"é—®é¢˜: {question}\\n\"\n",
    "                examples_text += f\"ä¸“å®¶æ¨ç†: {reasoning}\\n\"\n",
    "                examples_text += f\"ç­”æ¡ˆ: {answer}\\n\\n\"\n",
    "            else:\n",
    "                examples_text += f\"**Example {i}** [{subject}/{category}]:\\n\"\n",
    "                examples_text += f\"Question: {question}\\n\"\n",
    "                examples_text += f\"Expert Reasoning: {reasoning}\\n\"\n",
    "                examples_text += f\"Answer: {answer}\\n\\n\"\n",
    "        \n",
    "        if lang_code == \"zh\":\n",
    "            examples_text += \"ç°åœ¨è¯·è§£å†³ä»¥ä¸‹é—®é¢˜ï¼Œå‚è€ƒä¸Šè¿°ä¸“å®¶çš„æ¨ç†æ¨¡å¼ï¼š\\n\"\n",
    "        else:\n",
    "            examples_text += \"Now solve the following problem, following the expert reasoning patterns above:\\n\"\n",
    "        \n",
    "        return examples_text\n",
    "\n",
    "class AsyncGeminiPhysicsGenerator:\n",
    "    \"\"\"Async Gemini implementation of physics problem generator with feedback-enhanced regeneration\"\"\"\n",
    "    \n",
    "    def __init__(self, api_key: str, model: str = \"gemini-2.5-pro-preview-06-05\", \n",
    "                 labeled_samples_path: str = \"\", logger: Optional[logging.Logger] = None):\n",
    "        self.client = genai.Client(api_key=api_key)\n",
    "        self.model = model\n",
    "        self.example_manager = LabeledExampleManager(labeled_samples_path, logger) if labeled_samples_path else None\n",
    "        self.logger = logger or logging.getLogger(__name__)\n",
    "        \n",
    "        # Define safety settings\n",
    "        self.safety_settings = [\n",
    "            types.SafetySetting(\n",
    "                category=types.HarmCategory.HARM_CATEGORY_HARASSMENT,\n",
    "                threshold=types.HarmBlockThreshold.BLOCK_NONE\n",
    "            ),\n",
    "            types.SafetySetting(\n",
    "                category=types.HarmCategory.HARM_CATEGORY_HATE_SPEECH,\n",
    "                threshold=types.HarmBlockThreshold.BLOCK_NONE\n",
    "            ),\n",
    "            types.SafetySetting(\n",
    "                category=types.HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT,\n",
    "                threshold=types.HarmBlockThreshold.BLOCK_NONE\n",
    "            ),\n",
    "            types.SafetySetting(\n",
    "                category=types.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT,\n",
    "                threshold=types.HarmBlockThreshold.BLOCK_NONE\n",
    "            )\n",
    "        ]\n",
    "    \n",
    "    def _get_all_valid_categories(self) -> Set[str]:\n",
    "        \"\"\"Get all valid physics categories\"\"\"\n",
    "        categories = set()\n",
    "        for category_list in PHYSICS_CATEGORIES.values():\n",
    "            categories.update(category_list)\n",
    "        return categories\n",
    "    \n",
    "    def _validate_category(self, category: str) -> bool:\n",
    "        \"\"\"Validate physics category\"\"\"\n",
    "        return category in self._get_all_valid_categories()\n",
    "    \n",
    "    def _get_subject_context(self, subject_code: str, language: str = \"en\") -> tuple:\n",
    "        \"\"\"Get subject context and guidance\"\"\"\n",
    "        if subject_code and subject_code in PHYSICS_SUBJECTS:\n",
    "            subject_name = PHYSICS_SUBJECTS[subject_code]\n",
    "            subject_context = f\"{subject_code} ({subject_name})\"\n",
    "            subject_guidance = SUBJECT_GUIDANCE.get(subject_code, {}).get(language, \"Apply general physics principles\")\n",
    "        else:\n",
    "            if language == \"zh\":\n",
    "                subject_context = \"æœªæŒ‡å®šå­¦ç§‘\"\n",
    "                subject_guidance = \"åº”ç”¨ä¸€èˆ¬ç‰©ç†åŸç†\"\n",
    "            else:\n",
    "                subject_context = \"Unspecified subject\"\n",
    "                subject_guidance = \"Apply general physics principles\"\n",
    "        \n",
    "        return subject_context, subject_guidance\n",
    "    \n",
    "    def _get_category_expertise(self, category: str, language: str = \"en\") -> str:\n",
    "        \"\"\"Get category-specific expertise\"\"\"\n",
    "        lang_key = \"zh\" if language == \"zh\" else \"en\"\n",
    "        return CATEGORY_EXPERTISE.get(category, {}).get(lang_key, \"General physics principles\")\n",
    "    \n",
    "    def _format_previous_attempts_feedback(self, previous_attempts: List[str], evaluation: EvaluationResult, language: str = \"English\") -> str:\n",
    "        \"\"\"Format previous attempts and evaluation feedback for regeneration\"\"\"\n",
    "        if not previous_attempts or not evaluation:\n",
    "            return \"\"\n",
    "        \n",
    "        lang_code = \"zh\" if language == \"Chinese\" else \"en\"\n",
    "        \n",
    "        if lang_code == \"zh\":\n",
    "            feedback = \"\\n**å‰æ¬¡å°è¯•åˆ†æï¼š**\\n\\n\"\n",
    "            feedback += \"æ‚¨çš„å‰æ¬¡å°è¯•è¢«æ‹’ç»ã€‚ä»¥ä¸‹æ˜¯é—®é¢˜æ‰€åœ¨ï¼š\\n\\n\"\n",
    "            \n",
    "            # Show specific errors\n",
    "            errors = evaluation.physics_errors\n",
    "            if errors.physics_theorem_errors:\n",
    "                feedback += f\"âŒ **ç‰©ç†å®šç†é”™è¯¯**: {', '.join(errors.physics_theorem_errors)}\\n\"\n",
    "            if errors.condition_analysis_errors:\n",
    "                feedback += f\"âŒ **æ¡ä»¶åˆ†æé”™è¯¯**: {', '.join(errors.condition_analysis_errors)}\\n\"\n",
    "            if errors.process_understanding_errors:\n",
    "                feedback += f\"âŒ **è¿‡ç¨‹ç†è§£é”™è¯¯**: {', '.join(errors.process_understanding_errors)}\\n\"\n",
    "            if errors.calculation_errors:\n",
    "                feedback += f\"âŒ **è®¡ç®—é”™è¯¯**: {', '.join(errors.calculation_errors)}\\n\"\n",
    "            if errors.variable_relationship_errors:\n",
    "                feedback += f\"âŒ **å˜é‡å…³ç³»é”™è¯¯**: {', '.join(errors.variable_relationship_errors)}\\n\"\n",
    "            if errors.diagram_analysis_errors:\n",
    "                feedback += f\"âŒ **å›¾è¡¨åˆ†æé”™è¯¯**: {', '.join(errors.diagram_analysis_errors)}\\n\"\n",
    "            if errors.boundary_conditions_errors:\n",
    "                feedback += f\"âŒ **è¾¹ç•Œæ¡ä»¶é”™è¯¯**: {', '.join(errors.boundary_conditions_errors)}\\n\"\n",
    "            \n",
    "            # Show evaluation metrics\n",
    "            feedback += f\"\\n**è¯„ä¼°ç»“æœ**:\\n\"\n",
    "            feedback += f\"â€¢ ä¿¡å¿ƒåˆ†æ•°: {evaluation.confidence_score:.2f}\\n\"\n",
    "            feedback += f\"â€¢ è´¨é‡åˆ†æ•°: {evaluation.quality_score:.2f}\\n\"\n",
    "            feedback += f\"â€¢ ç­”æ¡ˆä¸€è‡´æ€§: {'æ˜¯' if evaluation.answer_consistency else 'å¦'}\\n\"\n",
    "            feedback += f\"â€¢ æ•°é‡çº§åˆç†æ€§: {'æ˜¯' if evaluation.magnitude_reasonable else 'å¦'}\\n\"\n",
    "            \n",
    "            # Show evaluation feedback\n",
    "            feedback += f\"\\n**è¯„ä¼°å¸ˆåé¦ˆ**: {evaluation.feedback_message}\\n\"\n",
    "            \n",
    "            # Show improvement suggestions\n",
    "            if evaluation.improvement_suggestions:\n",
    "                feedback += f\"\\n**æ”¹è¿›å»ºè®®**: {evaluation.improvement_suggestions}\\n\"\n",
    "            \n",
    "            # Show truncated previous solution\n",
    "            last_attempt = previous_attempts[-1]\n",
    "            truncated = last_attempt[:400] + \"...\" if len(last_attempt) > 400 else last_attempt\n",
    "            feedback += f\"\\n**å‰æ¬¡è§£ç­”ï¼ˆå·²æ‹’ç»ï¼‰**:\\n```\\n{truncated}\\n```\\n\"\n",
    "            feedback += \"\\n**é‡è¦æŒ‡ç¤º**: è¯·åœ¨æ–°è§£ç­”ä¸­è§£å†³ä¸Šè¿°é—®é¢˜ã€‚é¿å…é‡å¤ç›¸åŒé”™è¯¯ã€‚\\n\"\n",
    "            \n",
    "        else:\n",
    "            feedback = \"\\n**PREVIOUS ATTEMPT ANALYSIS:**\\n\\n\"\n",
    "            feedback += \"Your previous attempt was rejected. Here's what went wrong:\\n\\n\"\n",
    "            \n",
    "            # Show specific errors\n",
    "            errors = evaluation.physics_errors\n",
    "            if errors.physics_theorem_errors:\n",
    "                feedback += f\"âŒ **Physics Theorem Errors**: {', '.join(errors.physics_theorem_errors)}\\n\"\n",
    "            if errors.condition_analysis_errors:\n",
    "                feedback += f\"âŒ **Condition Analysis Errors**: {', '.join(errors.condition_analysis_errors)}\\n\"\n",
    "            if errors.process_understanding_errors:\n",
    "                feedback += f\"âŒ **Process Understanding Errors**: {', '.join(errors.process_understanding_errors)}\\n\"\n",
    "            if errors.calculation_errors:\n",
    "                feedback += f\"âŒ **Calculation Errors**: {', '.join(errors.calculation_errors)}\\n\"\n",
    "            if errors.variable_relationship_errors:\n",
    "                feedback += f\"âŒ **Variable Relationship Errors**: {', '.join(errors.variable_relationship_errors)}\\n\"\n",
    "            if errors.diagram_analysis_errors:\n",
    "                feedback += f\"âŒ **Diagram Analysis Errors**: {', '.join(errors.diagram_analysis_errors)}\\n\"\n",
    "            if errors.boundary_conditions_errors:\n",
    "                feedback += f\"âŒ **Boundary Conditions Errors**: {', '.join(errors.boundary_conditions_errors)}\\n\"\n",
    "            \n",
    "            # Show evaluation metrics\n",
    "            feedback += f\"\\n**Evaluation Metrics**:\\n\"\n",
    "            feedback += f\"â€¢ Confidence Score: {evaluation.confidence_score:.2f}\\n\"\n",
    "            feedback += f\"â€¢ Quality Score: {evaluation.quality_score:.2f}\\n\"\n",
    "            feedback += f\"â€¢ Answer Consistency: {'Yes' if evaluation.answer_consistency else 'No'}\\n\"\n",
    "            feedback += f\"â€¢ Magnitude Reasonable: {'Yes' if evaluation.magnitude_reasonable else 'No'}\\n\"\n",
    "            \n",
    "            # Show evaluation feedback\n",
    "            feedback += f\"\\n**Evaluator Feedback**: {evaluation.feedback_message}\\n\"\n",
    "            \n",
    "            # Show improvement suggestions\n",
    "            if evaluation.improvement_suggestions:\n",
    "                feedback += f\"\\n**Suggested Improvements**: {evaluation.improvement_suggestions}\\n\"\n",
    "            \n",
    "            # Show truncated previous solution\n",
    "            last_attempt = previous_attempts[-1]\n",
    "            truncated = last_attempt[:400] + \"...\" if len(last_attempt) > 400 else last_attempt\n",
    "            feedback += f\"\\n**Previous Solution (REJECTED)**:\\n```\\n{truncated}\\n```\\n\"\n",
    "            feedback += \"\\n**CRITICAL INSTRUCTIONS**: Address the above issues in your new solution. Avoid repeating the same mistakes.\\n\"\n",
    "        \n",
    "        return feedback\n",
    "    \n",
    "    def _format_generation_prompt(self, problem: Dict[str, Any], \n",
    "                                 previous_attempts: Optional[List[str]] = None,\n",
    "                                 evaluation_feedback: Optional[EvaluationResult] = None) -> str:\n",
    "        \"\"\"Format prompt for physics solution generation with optional feedback\"\"\"\n",
    "        language = problem.get(\"language\", \"English\")\n",
    "        lang_code = \"zh\" if language == \"Chinese\" else \"en\"\n",
    "        \n",
    "        # Extract problem details\n",
    "        question = problem.get(\"question\", \"\")\n",
    "        level = problem.get(\"level\", 1)\n",
    "        category = problem.get(\"img_category\", \"\")\n",
    "        subject_code = problem.get(\"subject\", \"\")\n",
    "        sig_figs = problem.get(\"sig_figs\", \"\")\n",
    "        caption = problem.get(\"caption\", \"\")\n",
    "        \n",
    "        # Get contexts\n",
    "        subject_context, subject_guidance = self._get_subject_context(subject_code, lang_code)\n",
    "        category_expertise = self._get_category_expertise(category, lang_code)\n",
    "        \n",
    "        # Get examples if available\n",
    "        examples_text = \"\"\n",
    "        if self.example_manager:\n",
    "            examples = self.example_manager.find_best_examples(problem, max_examples=3)\n",
    "            if examples:\n",
    "                self.logger.info(f\"âœ… Injecting {len(examples)} examples for problem {problem.get('index', 'Unknown')}.\")\n",
    "                examples_text = self.example_manager.format_examples_for_prompt(examples, language)\n",
    "            else:\n",
    "                self.logger.info(f\"âŒ No examples found for problem {problem.get('index', 'Unknown')}. Using empty examples.\")\n",
    "        \n",
    "        # Get feedback from previous attempts\n",
    "        feedback_text = \"\"\n",
    "        if previous_attempts and evaluation_feedback:\n",
    "            feedback_text = self._format_previous_attempts_feedback(previous_attempts, evaluation_feedback, language)\n",
    "        \n",
    "        # Format components\n",
    "        if lang_code == \"zh\":\n",
    "            prompt = f\"\"\"ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„ç‰©ç†å­¦å¯¼å¸ˆï¼Œå…·æœ‰æ·±åšçš„ç‰©ç†å­¦çŸ¥è¯†ã€‚\n",
    "\n",
    "**é—®é¢˜ä¿¡æ¯ï¼š**\n",
    "â€¢ éš¾åº¦ç­‰çº§ï¼š{level}/10\n",
    "â€¢ ç‰©ç†å­¦ç§‘ï¼š{subject_context}\n",
    "â€¢ é—®é¢˜ç±»åˆ«ï¼š{category}\n",
    "â€¢ è¯­è¨€ï¼š{language}\n",
    "{f\"â€¢ å›¾åƒè¯´æ˜ï¼š{caption}\" if caption else \"\"}\n",
    "{f\"â€¢ æœ‰æ•ˆæ•°å­—è¦æ±‚ï¼šç²¾ç¡®åˆ° {sig_figs} ä½æœ‰æ•ˆæ•°å­—\" if sig_figs else \"\"}\n",
    "\n",
    "**ä¸“ä¸šæŒ‡å¯¼ï¼š**\n",
    "â€¢ å­¦ç§‘é‡ç‚¹ï¼š{subject_guidance}\n",
    "â€¢ ç±»åˆ«ä¸“é•¿ï¼š{category_expertise}\n",
    "{feedback_text}\n",
    "{examples_text}\n",
    "\n",
    "**é—®é¢˜ï¼š**\n",
    "{question}\n",
    "\n",
    "**åˆ†æè¦æ±‚ï¼š**\n",
    "è¯·æä¾›å®Œæ•´çš„ç‰©ç†è§£ç­”ï¼ŒåŒ…æ‹¬ï¼š\n",
    "1. æ¸…æ™°çš„ç‰©ç†åˆ†æè¿‡ç¨‹\n",
    "2. å‡†ç¡®çš„æ•°å­¦æ¨å¯¼\n",
    "3. æœ€ç»ˆçš„æ•°å€¼ç­”æ¡ˆï¼ˆå¸¦é€‚å½“æœ‰æ•ˆæ•°å­—ï¼‰\n",
    "\n",
    "è¯·ç”¨ä»¥ä¸‹æ ¼å¼å›ç­”ï¼š\n",
    "<think>\n",
    "[åœ¨æ­¤æä¾›è¯¦ç»†çš„ç‰©ç†åˆ†æå’Œæ¨å¯¼è¿‡ç¨‹]\n",
    "</think>\n",
    "\n",
    "<answer>\n",
    "[åœ¨æ­¤æä¾›æœ€ç»ˆçš„æ•°å€¼ç­”æ¡ˆ]\n",
    "</answer>\"\"\"\n",
    "        else:\n",
    "            prompt = f\"\"\"You are an expert physics tutor with deep knowledge across all physics domains.\n",
    "\n",
    "**PROBLEM INFORMATION:**\n",
    "â€¢ Difficulty Level: {level}/10\n",
    "â€¢ Physics Subject: {subject_context}\n",
    "â€¢ Problem Category: {category}\n",
    "â€¢ Language: {language}\n",
    "{f\"â€¢ Image Caption: {caption}\" if caption else \"\"}\n",
    "{f\"â€¢ Significant Figures: Express answer to exactly {sig_figs} significant figures\" if sig_figs else \"\"}\n",
    "\n",
    "**EXPERT GUIDANCE:**\n",
    "â€¢ Subject Focus: {subject_guidance}\n",
    "â€¢ Category Expertise: {category_expertise}\n",
    "{feedback_text}\n",
    "{examples_text}\n",
    "\n",
    "**PROBLEM:**\n",
    "{question}\n",
    "\n",
    "**ANALYSIS REQUIREMENTS:**\n",
    "Provide a complete physics solution including:\n",
    "1. Clear physical analysis process\n",
    "2. Accurate mathematical derivations\n",
    "3. Final numerical answer (with appropriate significant figures)\n",
    "\n",
    "Please respond in the following format:\n",
    "<think>\n",
    "[Provide detailed physics analysis and derivation process here]\n",
    "</think>\n",
    "\n",
    "<answer>\n",
    "[Provide final numerical answer here]\n",
    "</answer>\"\"\"\n",
    "        \n",
    "        return prompt\n",
    "    \n",
    "    def _get_mime_type(self, file_path: str) -> str:\n",
    "        \"\"\"Get MIME type for image\"\"\"\n",
    "        ext = os.path.splitext(file_path)[1].lower()\n",
    "        mime_types = {\n",
    "            '.png': 'image/png',\n",
    "            '.jpg': 'image/jpeg',\n",
    "            '.jpeg': 'image/jpeg',\n",
    "            '.gif': 'image/gif',\n",
    "            '.webp': 'image/webp'\n",
    "        }\n",
    "        return mime_types.get(ext, 'image/png')\n",
    "    \n",
    "    def _prepare_generation_content(self, problem: Dict[str, Any], images_base_path: str = \"\",\n",
    "                                  previous_attempts: Optional[List[str]] = None,\n",
    "                                  evaluation_feedback: Optional[EvaluationResult] = None) -> List[Union[str, types.Part]]:\n",
    "        \"\"\"Prepare content for generation including images and feedback\"\"\"\n",
    "        prompt = self._format_generation_prompt(problem, previous_attempts, evaluation_feedback)\n",
    "        content = [prompt]\n",
    "        \n",
    "        # Add images if present\n",
    "        vision_relevance = problem.get('vision_relevance', '')\n",
    "        if vision_relevance in ['necessary', 'helpful', 'optional']:\n",
    "            image_paths = problem.get('image_path', [])\n",
    "            \n",
    "            for img_path in image_paths:\n",
    "                full_path = os.path.join(images_base_path, img_path) if images_base_path else img_path\n",
    "                \n",
    "                if os.path.exists(full_path):\n",
    "                    try:\n",
    "                        with open(full_path, 'rb') as img_file:\n",
    "                            image_data = img_file.read()\n",
    "                        \n",
    "                        mime_type = self._get_mime_type(full_path)\n",
    "                        image_part = types.Part.from_bytes(data=image_data, mime_type=mime_type)\n",
    "                        content.append(image_part)\n",
    "                        self.logger.debug(f\"âœ“ Added image: {img_path}\")\n",
    "                    except Exception as e:\n",
    "                        self.logger.warning(f\"âš ï¸ Failed to load image {img_path}: {e}\")\n",
    "        \n",
    "        return content\n",
    "    \n",
    "    async def generate_solution(self, problem: Dict[str, Any], images_base_path: str = \"\",\n",
    "                         previous_attempts: Optional[List[str]] = None,\n",
    "                         evaluation_feedback: Optional[EvaluationResult] = None) -> str:\n",
    "        \"\"\"Generate physics solution with optional feedback from previous attempts (async)\"\"\"\n",
    "        try:\n",
    "            content = self._prepare_generation_content(\n",
    "                problem, images_base_path, previous_attempts, evaluation_feedback\n",
    "            )\n",
    "            \n",
    "            # Create generation config\n",
    "            config = types.GenerateContentConfig(\n",
    "                temperature=0.1,\n",
    "                max_output_tokens=4096*10,\n",
    "                safety_settings=self.safety_settings,\n",
    "                thinking_config=types.ThinkingConfig(\n",
    "                    thinking_budget=4096,\n",
    "                    include_thoughts=True\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            # Generate content async\n",
    "            response = await asyncio.to_thread(\n",
    "                self.client.models.generate_content,\n",
    "                model=self.model,\n",
    "                contents=content,\n",
    "                config=config\n",
    "            )\n",
    "            \n",
    "            if hasattr(response, 'text') and response.text:\n",
    "                return response.text\n",
    "            else:\n",
    "                return \"Error: No response generated\"\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Generation failed: {e}\")\n",
    "            return f\"Generation error: {str(e)}\"\n",
    "\n",
    "class AsyncGeminiPhysicsEvaluator:\n",
    "    \"\"\"Async Gemini implementation of physics solution evaluator\"\"\"\n",
    "    \n",
    "    def __init__(self, api_key: str, model: str = \"gemini-2.5-pro-preview-06-05\", \n",
    "                 logger: Optional[logging.Logger] = None):\n",
    "        self.client = genai.Client(api_key=api_key)\n",
    "        self.model = model\n",
    "        self.logger = logger or logging.getLogger(__name__)\n",
    "        \n",
    "        # Define safety settings\n",
    "        self.safety_settings = [\n",
    "            types.SafetySetting(\n",
    "                category=types.HarmCategory.HARM_CATEGORY_HARASSMENT,\n",
    "                threshold=types.HarmBlockThreshold.BLOCK_NONE\n",
    "            ),\n",
    "            types.SafetySetting(\n",
    "                category=types.HarmCategory.HARM_CATEGORY_HATE_SPEECH,\n",
    "                threshold=types.HarmBlockThreshold.BLOCK_NONE\n",
    "            ),\n",
    "            types.SafetySetting(\n",
    "                category=types.HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT,\n",
    "                threshold=types.HarmBlockThreshold.BLOCK_NONE\n",
    "            ),\n",
    "            types.SafetySetting(\n",
    "                category=types.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT,\n",
    "                threshold=types.HarmBlockThreshold.BLOCK_NONE\n",
    "            )\n",
    "        ]\n",
    "\n",
    "    def _get_evaluator_system_prompt(self, language: str = \"English\") -> str:\n",
    "        \"\"\"Get system prompt for evaluation\"\"\"\n",
    "        \n",
    "        if language == \"Chinese\":\n",
    "            return \"\"\"ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„ç‰©ç†å­¦ä¸“å®¶å’Œè§£ç­”è¯„ä¼°å¸ˆã€‚ä½ çš„ä»»åŠ¡æ˜¯è¯„ä¼°ä»é›¶ç”Ÿæˆçš„ç‰©ç†è§£ç­”è´¨é‡ã€‚\n",
    "\n",
    "**è¯„ä¼°ç›®æ ‡ï¼š** å†³å®šæ˜¯å¦æ¥å—ç”Ÿæˆçš„è§£ç­”ï¼Œæˆ–éœ€è¦é‡æ–°ç”Ÿæˆã€‚\n",
    "\n",
    "**æ™ºèƒ½æ¥å—æ ‡å‡†ï¼š**\n",
    "- **ç»ä¸æ¥å—ä¿¡å¿ƒ < 30%** çš„è§£ç­”ï¼ˆå¿…é¡»é‡æ–°ç”Ÿæˆï¼‰\n",
    "- **è°¨æ…æ¥å—ä¿¡å¿ƒ 30-50%** çš„è§£ç­”ï¼ˆä»…å½“ç‰©ç†åŸç†æ­£ç¡®ä¸”æ— é‡å¤§é”™è¯¯æ—¶ï¼‰\n",
    "- **ä¼˜å…ˆæ¥å—ä¿¡å¿ƒ > 50%** çš„è§£ç­”ï¼ˆå³ä½¿æœ‰å°çš„æ ¼å¼é—®é¢˜ï¼‰\n",
    "- **é«˜çº§é—®é¢˜ï¼ˆL7+ï¼‰å’Œè§†è§‰é—®é¢˜**ï¼šä¿¡å¿ƒé˜ˆå€¼æé«˜10%\n",
    "\n",
    "**ç‰©ç†é”™è¯¯åˆ†ç±»ï¼š**\n",
    "- ç‰©ç†å®šç†é”™è¯¯ï¼šåº”ç”¨é”™è¯¯çš„å®šå¾‹/å…¬å¼\n",
    "- æ¡ä»¶åˆ†æé”™è¯¯ï¼šè¯¯è¯†åˆ«åŠ›ã€è¾¹ç•Œã€ç³»ç»Ÿè®¾ç½®\n",
    "- è¿‡ç¨‹ç†è§£é”™è¯¯ï¼šè¯¯è§£ç‰©ç†ç°è±¡å‘å±•è¿‡ç¨‹\n",
    "- è®¡ç®—é”™è¯¯ï¼šæ•°å­¦æ¨å¯¼ä¸­çš„é”™è¯¯\n",
    "- å˜é‡å…³ç³»é”™è¯¯ï¼šé‡ä¹‹é—´çš„é”™è¯¯ä¾èµ–å…³ç³»\n",
    "- å›¾è¡¨åˆ†æé”™è¯¯ï¼šè¯¯è¯»è§†è§‰ä¿¡æ¯\n",
    "- è¾¹ç•Œæ¡ä»¶é”™è¯¯ï¼šå¿½ç•¥çº¦æŸ/é™åˆ¶\n",
    "\n",
    "**å†³ç­–é€»è¾‘ï¼š**\n",
    "- æ¥å—ï¼šä¿¡å¿ƒ â‰¥ 50% ä¸”æ— é‡å¤§ç‰©ç†é”™è¯¯ï¼Œæˆ–ä¿¡å¿ƒ 30-50% ä¸”è§£ç­”åŸºæœ¬æ­£ç¡®\n",
    "- æ‹’ç»ï¼šä¿¡å¿ƒ < 30%ï¼Œæˆ–æœ‰é‡å¤§ç‰©ç†åŸç†é”™è¯¯ï¼Œæˆ–ç­”æ¡ˆæ˜æ˜¾ä¸åˆç†\n",
    "\n",
    "è¯·è¯šå®è¯„ä¼°ä½ çš„ä¿¡å¿ƒæ°´å¹³ï¼Œè¿™ç›´æ¥å½±å“æ¥å—/æ‹’ç»å†³å®šã€‚\"\"\"\n",
    "        \n",
    "        else:\n",
    "            return \"\"\"You are an expert physics specialist and solution evaluator. Your task is to assess the quality of from-scratch generated physics solutions.\n",
    "\n",
    "**EVALUATION GOAL:** Decide whether to accept the generated solution or regenerate.\n",
    "\n",
    "**Smart Acceptance Criteria:**\n",
    "- **NEVER ACCEPT confidence < 30%** solutions (must regenerate)\n",
    "- **CAUTIOUSLY ACCEPT confidence 30-50%** solutions (only if physics principles correct with no major errors)\n",
    "- **READILY ACCEPT confidence > 50%** solutions (even with minor formatting issues)\n",
    "- **Advanced problems (L7+) and vision problems**: Raise confidence thresholds by 10%\n",
    "\n",
    "**Physics Error Classification:**\n",
    "- Physics theorem errors: Wrong laws/formulas applied\n",
    "- Condition analysis errors: Misidentified forces, boundaries, system setup\n",
    "- Process understanding errors: Misunderstood physical phenomena development\n",
    "- Calculation errors: Mathematical derivation mistakes\n",
    "- Variable relationship errors: Wrong dependencies between quantities\n",
    "- Diagram analysis errors: Misread visual information\n",
    "- Boundary conditions errors: Ignored constraints/limits\n",
    "\n",
    "**Decision Logic:**\n",
    "- REJECT: Confidence < 60% OR any major physics errors\n",
    "- ACCEPT: Confidence â‰¥ 60% AND zero major errors\n",
    "\n",
    "Please honestly assess your confidence level - this directly affects accept/reject decision.\"\"\"\n",
    "    \n",
    "    def _format_evaluation_prompt(self, problem: Dict[str, Any], solution: str) -> str:\n",
    "        \"\"\"Format evaluation prompt\"\"\"\n",
    "        language = problem.get(\"language\", \"English\")\n",
    "        \n",
    "        # Get problem details\n",
    "        question = problem.get(\"question\", \"N/A\")\n",
    "        level = problem.get(\"level\", \"Unknown\")\n",
    "        category = problem.get(\"img_category\", \"Unknown\")\n",
    "        subject_code = problem.get(\"subject\", \"\")\n",
    "        caption = problem.get(\"caption\", \"\")\n",
    "        sig_figs = problem.get(\"sig_figs\", \"\")\n",
    "        \n",
    "        # Format subject info\n",
    "        subject_info = \"\"\n",
    "        if subject_code and subject_code in PHYSICS_SUBJECTS:\n",
    "            subject_name = PHYSICS_SUBJECTS[subject_code]\n",
    "            if language == \"Chinese\":\n",
    "                subject_info = f\"\\nç‰©ç†å­¦ç§‘: {subject_code} ({subject_name})\"\n",
    "            else:\n",
    "                subject_info = f\"\\nPhysics Subject: {subject_code} ({subject_name})\"\n",
    "        \n",
    "        # Format caption info\n",
    "        caption_info = \"\"\n",
    "        if caption:\n",
    "            if language == \"Chinese\":\n",
    "                caption_info = f\"\\nå›¾åƒè¯´æ˜: {caption}\"\n",
    "            else:\n",
    "                caption_info = f\"\\nImage Caption: {caption}\"\n",
    "        \n",
    "        if language == \"Chinese\":\n",
    "            prompt = f\"\"\"**ç‰©ç†é—®é¢˜ï¼š**\n",
    "é—®é¢˜: {question}\n",
    "éš¾åº¦ç­‰çº§: {level}/10\n",
    "é—®é¢˜ç±»åˆ«: {category}{subject_info}\n",
    "è¯­è¨€: {language}{caption_info}\n",
    "æœ‰æ•ˆæ•°å­—è¦æ±‚: {sig_figs if sig_figs else \"æœªæŒ‡å®š\"}\n",
    "\n",
    "**ç”Ÿæˆçš„è§£ç­”ï¼š**\n",
    "{solution}\n",
    "\n",
    "**è¯„ä¼°ä»»åŠ¡ï¼š**\n",
    "è¯„ä¼°è¿™ä¸ªä»é›¶ç”Ÿæˆçš„ç‰©ç†è§£ç­”è´¨é‡ã€‚å†³å®šæ˜¯å¦æ¥å—æ­¤è§£ç­”æˆ–éœ€è¦é‡æ–°ç”Ÿæˆã€‚\n",
    "\n",
    "**è€ƒè™‘å› ç´ ï¼š**\n",
    "1. ç‰©ç†åŸç†åº”ç”¨çš„æ­£ç¡®æ€§ï¼ˆç‰¹åˆ«æ˜¯{subject_code}å­¦ç§‘åŸç†ï¼‰\n",
    "2. æ•°å­¦æ¨å¯¼å’Œè®¡ç®—çš„å‡†ç¡®æ€§\n",
    "3. æ¨ç†è¿‡ç¨‹çš„é€»è¾‘æ€§å’Œå®Œæ•´æ€§\n",
    "4. æœ€ç»ˆç­”æ¡ˆçš„åˆç†æ€§ï¼ˆæ•°é‡çº§ã€å•ä½ã€æ–¹å‘ï¼‰\n",
    "5. å¦‚æœæœ‰å›¾åƒï¼šè§†è§‰ä¿¡æ¯çš„æ­£ç¡®è§£é‡Š\n",
    "6. æœ‰æ•ˆæ•°å­—è¦æ±‚çš„éµå®ˆï¼ˆå¦‚æœæŒ‡å®šï¼‰\n",
    "7. æ•´ä½“è§£ç­”è´¨é‡å’Œæ¸…æ™°åº¦\n",
    "\n",
    "è¯·æä¾›è¯¦ç»†çš„è¯„ä¼°ç»“æœã€‚\"\"\"\n",
    "        else:\n",
    "            prompt = f\"\"\"**PHYSICS PROBLEM:**\n",
    "Question: {question}\n",
    "Level: {level}/10\n",
    "Category: {category}{subject_info}\n",
    "Language: {language}{caption_info}\n",
    "Required Significant Figures: {sig_figs if sig_figs else \"Not specified\"}\n",
    "\n",
    "**GENERATED SOLUTION:**\n",
    "{solution}\n",
    "\n",
    "**EVALUATION TASK:**\n",
    "Assess the quality of this from-scratch generated physics solution. Decide whether to accept or regenerate.\n",
    "\n",
    "**Consider:**\n",
    "1. Correctness of physics principle applications (especially {subject_code} subject principles)\n",
    "2. Accuracy of mathematical derivations and calculations\n",
    "3. Logical consistency and completeness of reasoning\n",
    "4. Reasonableness of final answer (magnitude, units, direction)\n",
    "5. If images provided: correct interpretation of visual information\n",
    "6. Compliance with significant figures requirements (if specified)\n",
    "7. Overall solution quality and clarity\n",
    "\n",
    "Please provide detailed evaluation results.\"\"\"\n",
    "        \n",
    "        return prompt\n",
    "    \n",
    "    def _prepare_evaluation_content(self, problem: Dict[str, Any], solution: str, images_base_path: str = \"\") -> List[Union[str, types.Part]]:\n",
    "        \"\"\"Prepare evaluation content including images\"\"\"\n",
    "        prompt = self._format_evaluation_prompt(problem, solution)\n",
    "        content = [prompt]\n",
    "        \n",
    "        # Add images if present\n",
    "        vision_relevance = problem.get('vision_relevance', '')\n",
    "        if vision_relevance in ['necessary', 'helpful', 'optional']:\n",
    "            image_paths = problem.get('image_path', [])\n",
    "            \n",
    "            for img_path in image_paths:\n",
    "                full_path = os.path.join(images_base_path, img_path) if images_base_path else img_path\n",
    "                \n",
    "                if os.path.exists(full_path):\n",
    "                    try:\n",
    "                        with open(full_path, 'rb') as img_file:\n",
    "                            image_data = img_file.read()\n",
    "                        \n",
    "                        mime_type = self._get_mime_type(full_path)\n",
    "                        image_part = types.Part.from_bytes(data=image_data, mime_type=mime_type)\n",
    "                        content.append(image_part)\n",
    "                    except Exception as e:\n",
    "                        self.logger.warning(f\"âš ï¸ Failed to load image {img_path}: {e}\")\n",
    "        return content\n",
    "    \n",
    "    def _get_mime_type(self, file_path: str) -> str:\n",
    "        \"\"\"Get MIME type for image\"\"\"\n",
    "        ext = os.path.splitext(file_path)[1].lower()\n",
    "        mime_types = {\n",
    "            '.png': 'image/png',\n",
    "            '.jpg': 'image/jpeg',\n",
    "            '.jpeg': 'image/jpeg',\n",
    "            '.gif': 'image/gif',\n",
    "            '.webp': 'image/webp'\n",
    "        }\n",
    "        return mime_types.get(ext, 'image/png')\n",
    "    \n",
    "    async def evaluate_solution(self, problem: Dict[str, Any], solution: str, images_base_path: str = \"\") -> EvaluationResult:\n",
    "        \"\"\"Evaluate physics solution (async)\"\"\"\n",
    "        try:\n",
    "            content = self._prepare_evaluation_content(problem, solution, images_base_path)\n",
    "            system_prompt = self._get_evaluator_system_prompt(problem.get(\"language\", \"English\"))\n",
    "            \n",
    "            # Create generation config for structured output\n",
    "            config = types.GenerateContentConfig(\n",
    "                temperature=0.1,\n",
    "                max_output_tokens=4096*5,\n",
    "                safety_settings=self.safety_settings,\n",
    "                system_instruction=system_prompt,\n",
    "                response_mime_type=\"application/json\",\n",
    "                response_schema=EvaluationResult,\n",
    "            )\n",
    "            \n",
    "            # Generate evaluation async\n",
    "            response = await asyncio.to_thread(\n",
    "                self.client.models.generate_content,\n",
    "                model=self.model,\n",
    "                contents=content,\n",
    "                config=config\n",
    "            )\n",
    "            \n",
    "            if hasattr(response, 'text') and response.text:\n",
    "                # Parse the structured response\n",
    "                try:\n",
    "                    result_data = json.loads(response.text)\n",
    "                    result = EvaluationResult(**result_data)\n",
    "                except (json.JSONDecodeError, Exception) as e:\n",
    "                    self.logger.warning(f\"Failed to parse structured output: {e}\")\n",
    "                    # Fallback to default evaluation\n",
    "                    result = EvaluationResult(\n",
    "                        decision=EvaluationDecision.ACCEPT,\n",
    "                        confidence_score=0.5,\n",
    "                        quality_score=0.5,\n",
    "                        physics_errors=PhysicsErrorAnalysis(),\n",
    "                        answer_consistency=True,\n",
    "                        magnitude_reasonable=True,\n",
    "                        feedback_message=\"Evaluation parsing failed\"\n",
    "                    )\n",
    "            else:\n",
    "                result = EvaluationResult(\n",
    "                    decision=EvaluationDecision.ACCEPT,\n",
    "                    confidence_score=0.5,\n",
    "                    quality_score=0.5,\n",
    "                    physics_errors=PhysicsErrorAnalysis(),\n",
    "                    answer_consistency=True,\n",
    "                    magnitude_reasonable=True,\n",
    "                    feedback_message=\"No response generated\"\n",
    "                )\n",
    "            \n",
    "            # Apply confidence and error-based decision logic\n",
    "            return self._apply_decision_logic(result, problem)\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Evaluation failed: {e}\")\n",
    "            # Default to accept to avoid infinite loops\n",
    "            return EvaluationResult(\n",
    "                decision=EvaluationDecision.ACCEPT,\n",
    "                confidence_score=0.5,\n",
    "                quality_score=0.5,\n",
    "                physics_errors=PhysicsErrorAnalysis(),\n",
    "                answer_consistency=True,\n",
    "                magnitude_reasonable=True,\n",
    "                feedback_message=f\"Evaluation failed: {e}\"\n",
    "            )\n",
    "    \n",
    "    def _apply_decision_logic(self, result: EvaluationResult, problem: Dict[str, Any]) -> EvaluationResult:\n",
    "        \"\"\"Apply enhanced decision logic with confidence thresholds\"\"\"\n",
    "        original_decision = result.decision\n",
    "        confidence = result.confidence_score\n",
    "        level = problem.get(\"level\", 1)\n",
    "        vision_relevance = problem.get(\"vision_relevance\", \"\")\n",
    "        \n",
    "        # Count major physics errors\n",
    "        errors = result.physics_errors\n",
    "        major_errors = (\n",
    "            len(errors.physics_theorem_errors) +\n",
    "            len(errors.condition_analysis_errors) +\n",
    "            len(errors.process_understanding_errors) +\n",
    "            len(errors.calculation_errors) +\n",
    "            len(errors.variable_relationship_errors) +\n",
    "            len(errors.diagram_analysis_errors)\n",
    "        )\n",
    "        \n",
    "        # Adjust thresholds for advanced/vision problems\n",
    "        confidence_threshold = 0.6\n",
    "        if level >= 7 or vision_relevance in ['necessary', 'helpful']:\n",
    "            confidence_threshold = 0.6\n",
    "        \n",
    "        # Collect rejection reasons\n",
    "        rejection_reasons = []\n",
    "        \n",
    "        # Check for rejection conditions\n",
    "        if confidence < confidence_threshold:\n",
    "            rejection_reasons.append(f\"Low confidence ({confidence:.2f} < {confidence_threshold})\")\n",
    "        \n",
    "        if major_errors > 0:\n",
    "            rejection_reasons.append(f\"{major_errors} major physics error(s)\")\n",
    "        \n",
    "        # Make decision based on rejection reasons\n",
    "        if rejection_reasons:\n",
    "            final_decision = EvaluationDecision.REJECT\n",
    "            override_reason = \" + \".join(rejection_reasons)\n",
    "        else:\n",
    "            final_decision = EvaluationDecision.ACCEPT\n",
    "            override_reason = f\"Good confidence ({confidence:.2f}) + no major errors\"\n",
    "        \n",
    "        # Update result with final decision\n",
    "        result.decision = final_decision\n",
    "        \n",
    "        if override_reason and original_decision != final_decision:\n",
    "            result.feedback_message += f\" [Override: {override_reason}]\"\n",
    "        elif override_reason:\n",
    "            result.feedback_message += f\" [Confirmed: {override_reason}]\"\n",
    "        \n",
    "        return result\n",
    "\n",
    "class AsyncGeminiFromScratchSolver:\n",
    "    \"\"\"Async Gemini implementation of from-scratch physics solver with example injection and proper logging\"\"\"\n",
    "    \n",
    "    def __init__(self, api_key: str, \n",
    "                 generator_model: str = \"gemini-2.5-pro-preview-06-05\",\n",
    "                 evaluator_model: str = \"gemini-2.5-pro-preview-06-05\",\n",
    "                 max_iterations: int = 3,\n",
    "                 images_base_path: str = \"\",\n",
    "                 labeled_samples_path: str = \"\",\n",
    "                 logger: Optional[logging.Logger] = None,\n",
    "                 verbose: bool = True):\n",
    "        \n",
    "        self.generator = AsyncGeminiPhysicsGenerator(api_key, generator_model, labeled_samples_path, logger)\n",
    "        self.evaluator = AsyncGeminiPhysicsEvaluator(api_key=api_key, model=evaluator_model, logger=logger)\n",
    "        self.max_iterations = max_iterations\n",
    "        self.images_base_path = images_base_path\n",
    "        self.logger = logger or logging.getLogger(__name__)\n",
    "        self.verbose = verbose\n",
    "    \n",
    "    async def _generator_step(self, state: SolutionState) -> SolutionState:\n",
    "        \"\"\"Generator step with feedback-enhanced regeneration (async)\"\"\"\n",
    "        try:\n",
    "            # Use generation_history length instead of iteration_count\n",
    "            is_regeneration = len(state[\"generation_history\"]) > 0\n",
    "            \n",
    "            if is_regeneration:\n",
    "                attempt_num = len(state[\"generation_history\"]) + 1\n",
    "                self.logger.info(f\"ğŸ”„ Regeneration attempt {attempt_num} with feedback for problem {state['problem'].get('index', 'Unknown')}\")\n",
    "                previous_attempts = state[\"generation_history\"]\n",
    "                evaluation_feedback = state[\"evaluation_result\"]\n",
    "            else:\n",
    "                self.logger.info(f\"ğŸ†• Initial generation attempt for problem {state['problem'].get('index', 'Unknown')}\")\n",
    "                previous_attempts = None\n",
    "                evaluation_feedback = None\n",
    "            \n",
    "            # Generate solution with optional feedback\n",
    "            solution = await self.generator.generate_solution(\n",
    "                state[\"problem\"], \n",
    "                self.images_base_path,\n",
    "                previous_attempts=previous_attempts,\n",
    "                evaluation_feedback=evaluation_feedback\n",
    "            )\n",
    "            \n",
    "            state[\"current_solution\"] = solution\n",
    "            state[\"generation_history\"].append(solution)\n",
    "            \n",
    "            # Enhanced logging for regeneration\n",
    "            if is_regeneration and evaluation_feedback:\n",
    "                errors = evaluation_feedback.physics_errors\n",
    "                error_count = (\n",
    "                    len(errors.physics_theorem_errors) +\n",
    "                    len(errors.condition_analysis_errors) +\n",
    "                    len(errors.process_understanding_errors) +\n",
    "                    len(errors.calculation_errors) +\n",
    "                    len(errors.variable_relationship_errors) +\n",
    "                    len(errors.diagram_analysis_errors)\n",
    "                )\n",
    "                self.logger.info(f\"âœ… Regenerated solution addressing {error_count} previous errors\")\n",
    "                self.logger.info(f\"   Previous confidence: {evaluation_feedback.confidence_score:.2f}\")\n",
    "            else:\n",
    "                self.logger.info(f\"âœ… Generated solution for problem {state['problem'].get('index', 'Unknown')}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"âŒ Generation failed: {e}\")\n",
    "            state[\"current_solution\"] = f\"Generation error: {str(e)}\"\n",
    "        \n",
    "        return state\n",
    "        \n",
    "    async def _evaluator_step(self, state: SolutionState) -> SolutionState:\n",
    "        \"\"\"Evaluator step (async)\"\"\"\n",
    "        if not state[\"current_solution\"]:\n",
    "            state[\"evaluation_result\"] = EvaluationResult(\n",
    "                decision=EvaluationDecision.REJECT,\n",
    "                confidence_score=0.0,\n",
    "                quality_score=0.0,\n",
    "                physics_errors=PhysicsErrorAnalysis(),\n",
    "                answer_consistency=False,\n",
    "                magnitude_reasonable=False,\n",
    "                feedback_message=\"No solution provided\"\n",
    "            )\n",
    "            return state\n",
    "        \n",
    "        try:\n",
    "            result = await self.evaluator.evaluate_solution(\n",
    "                state[\"problem\"], \n",
    "                state[\"current_solution\"], \n",
    "                self.images_base_path\n",
    "            )\n",
    "            \n",
    "            state[\"evaluation_result\"] = result\n",
    "            \n",
    "            # Count major errors for reporting\n",
    "            errors = result.physics_errors\n",
    "            major_errors = (\n",
    "                len(errors.physics_theorem_errors) +\n",
    "                len(errors.condition_analysis_errors) +\n",
    "                len(errors.process_understanding_errors) +\n",
    "                len(errors.calculation_errors) +\n",
    "                len(errors.variable_relationship_errors) +\n",
    "                len(errors.diagram_analysis_errors)\n",
    "            )\n",
    "            \n",
    "            self.logger.info(f\"ğŸ“Š Evaluation: {result.decision.value.upper()} \"\n",
    "                           f\"(Confidence: {result.confidence_score:.2f}, \"\n",
    "                           f\"Quality: {result.quality_score:.2f}, \"\n",
    "                           f\"Errors: {major_errors})\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.warning(f\"âš ï¸ Evaluation failed: {e}\")\n",
    "            state[\"evaluation_result\"] = EvaluationResult(\n",
    "                decision=EvaluationDecision.ACCEPT,\n",
    "                confidence_score=0.5,\n",
    "                quality_score=0.5,\n",
    "                physics_errors=PhysicsErrorAnalysis(),\n",
    "                answer_consistency=True,\n",
    "                magnitude_reasonable=True,\n",
    "                feedback_message=f\"Evaluation failed: {e}\"\n",
    "            )\n",
    "        \n",
    "        return state\n",
    "    \n",
    "    def _routing_logic(self, state: SolutionState) -> str:\n",
    "        attempts = len(state[\"generation_history\"])\n",
    "        \"\"\"Routing logic after evaluation\"\"\"\n",
    "        if attempts >= state[\"max_iterations\"]:\n",
    "            self.logger.warning(f\"âš ï¸ Max iterations ({state['max_iterations']}) reached for problem {state['problem'].get('index', 'Unknown')}\")            \n",
    "            return \"max_iterations\"\n",
    "        \n",
    "        if state[\"evaluation_result\"] and state[\"evaluation_result\"].decision == EvaluationDecision.ACCEPT:\n",
    "            return \"accept\"\n",
    "        else:\n",
    "            return \"reject\"\n",
    "    \n",
    "    async def solve_problem(self, problem: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"Solve a single problem (async)\"\"\"\n",
    "        initial_state = {\n",
    "            \"problem\": problem,\n",
    "            \"current_solution\": None,\n",
    "            \"evaluation_result\": None,\n",
    "            \"final_solution\": None,\n",
    "            \"iteration_count\": 0,\n",
    "            \"max_iterations\": self.max_iterations,\n",
    "            \"generation_history\": []\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            # Simple async workflow loop\n",
    "            state = initial_state\n",
    "            \n",
    "            while True:\n",
    "                # Generation step\n",
    "                state = await self._generator_step(state)\n",
    "                \n",
    "                # Evaluation step\n",
    "                state = await self._evaluator_step(state)\n",
    "                \n",
    "                # Routing logic\n",
    "                decision = self._routing_logic(state)\n",
    "                \n",
    "                if decision in [\"accept\", \"max_iterations\"]:\n",
    "                    state[\"final_solution\"] = state[\"current_solution\"]\n",
    "                    state[\"iteration_count\"] += 1\n",
    "                    break\n",
    "                elif decision == \"reject\":\n",
    "                    # Continue loop for regeneration\n",
    "                    continue\n",
    "            \n",
    "            result = problem.copy()\n",
    "            result[\"prediction\"] = state[\"final_solution\"]\n",
    "            result[\"iterations_used\"] = state[\"iteration_count\"]\n",
    "            result[\"total_generations\"] = len(state[\"generation_history\"])\n",
    "            result[\"generation_history\"] = state[\"generation_history\"]\n",
    "            \n",
    "            if state[\"evaluation_result\"]:\n",
    "                eval_result = state[\"evaluation_result\"]\n",
    "                result[\"final_decision\"] = eval_result.decision.value\n",
    "                result[\"confidence_score\"] = eval_result.confidence_score\n",
    "                result[\"quality_score\"] = eval_result.quality_score\n",
    "                result[\"evaluation_feedback\"] = eval_result.feedback_message\n",
    "            else:\n",
    "                result[\"final_decision\"] = \"unknown\"\n",
    "            \n",
    "            return result\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"âŒ Workflow failed for problem {problem.get('index', 'Unknown')}: {e}\")\n",
    "            result = problem.copy()\n",
    "            result[\"prediction\"] = f\"Workflow failed: {str(e)}\"\n",
    "            result[\"error\"] = str(e)\n",
    "            return result\n",
    "\n",
    "# Setup logging\n",
    "def setup_logging(log_file: str = \"gemini_physics_solver.log\", verbose: bool = True):\n",
    "    \"\"\"Setup logging configuration\"\"\"\n",
    "    os.makedirs(os.path.dirname(log_file) if os.path.dirname(log_file) else '.', exist_ok=True)\n",
    "    \n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "        handlers=[\n",
    "            logging.FileHandler(log_file, encoding='utf-8'),\n",
    "            logging.StreamHandler() if verbose else logging.NullHandler()\n",
    "        ],\n",
    "        force=True\n",
    "    )\n",
    "    return logging.getLogger(__name__)\n",
    "\n",
    "async def solve_batch_async(solver: AsyncGeminiFromScratchSolver, batch: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n",
    "    \"\"\"Solve a batch of problems asynchronously with timeout protection\"\"\"\n",
    "    tasks = [solver.solve_problem(problem) for problem in batch]\n",
    "    \n",
    "    try:\n",
    "        # Add timeout to prevent hanging batches (10 minutes per batch)\n",
    "        results = await asyncio.wait_for(\n",
    "            asyncio.gather(*tasks, return_exceptions=True),\n",
    "            timeout=12000  # 10 minutes timeout for entire batch\n",
    "        )\n",
    "    except asyncio.TimeoutError:\n",
    "        # Handle batch timeout\n",
    "        solver.logger.error(f\"âŒ Batch timed out after 10 minutes\")\n",
    "        # Create timeout results for all problems in batch\n",
    "        results = []\n",
    "        for problem in batch:\n",
    "            timeout_result = problem.copy()\n",
    "            timeout_result[\"prediction\"] = \"Batch timeout error\"\n",
    "            timeout_result[\"error\"] = \"Batch processing timed out\"\n",
    "            results.append(timeout_result)\n",
    "        return results\n",
    "    \n",
    "    # Handle exceptions\n",
    "    processed_results = []\n",
    "    for i, result in enumerate(results):\n",
    "        if isinstance(result, Exception):\n",
    "            # Handle exception by creating error result\n",
    "            problem = batch[i]\n",
    "            error_result = problem.copy()\n",
    "            error_result[\"prediction\"] = f\"Async error: {str(result)}\"\n",
    "            error_result[\"error\"] = str(result)\n",
    "            processed_results.append(error_result)\n",
    "        else:\n",
    "            processed_results.append(result)\n",
    "    \n",
    "    return processed_results\n",
    "\n",
    "async def run_async_gemini_from_scratch_solving(problems: List[Dict[str, Any]], \n",
    "                                  output_file: str = \"gemini_physics_results.json\",\n",
    "                                  images_base_path: str = \"\",\n",
    "                                  labeled_samples_path: str = \"\",\n",
    "                                  generator_model: str = \"gemini-2.5-pro-preview-06-05\",\n",
    "                                  evaluator_model: str = \"gemini-2.5-pro-preview-06-05\",\n",
    "                                  max_iterations: int = 3,\n",
    "                                  log_file: str = \"gemini_physics_solver.log\",\n",
    "                                  verbose: bool = True,\n",
    "                                  console_verbosity: str = \"minimal\",\n",
    "                                  batch_size: int = 5) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Main async function to solve physics problems in batches using Gemini models\n",
    "    \"\"\"\n",
    "    \n",
    "    # Setup logging\n",
    "    logger = setup_logging(log_file, verbose and console_verbosity != \"silent\")\n",
    "    \n",
    "    # Check for existing results\n",
    "    existing_results = []\n",
    "    processed_indices = set()\n",
    "    \n",
    "    if os.path.exists(output_file):\n",
    "        logger.info(f\"ğŸ“ Found existing results: {output_file}\")\n",
    "        try:\n",
    "            with open(output_file, 'r', encoding='utf-8') as f:\n",
    "                existing_results = json.load(f)\n",
    "            processed_indices = {result.get('index') for result in existing_results}\n",
    "            logger.info(f\"âœ… Loaded {len(existing_results)} existing results\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"âš ï¸ Error loading existing results: {e}\")\n",
    "            existing_results = []\n",
    "            processed_indices = set()\n",
    "    \n",
    "    # Filter problems to solve\n",
    "    problems_to_solve = [p for p in problems if p.get('index') not in processed_indices]\n",
    "    \n",
    "    logger.info(f\"ğŸ¯ Problems to solve: {len(problems_to_solve)}\")\n",
    "    logger.info(f\"ğŸ“Š Total: {len(problems)}, Done: {len(processed_indices)}, Remaining: {len(problems_to_solve)}\")\n",
    "    logger.info(f\"âš¡ Batch size: {batch_size}\")\n",
    "    \n",
    "    if labeled_samples_path:\n",
    "        logger.info(f\"ğŸ” Using labeled examples from: {labeled_samples_path}\")\n",
    "    else:\n",
    "        logger.info(\"ğŸ“ No labeled examples provided - using base prompts only\")\n",
    "    \n",
    "    if len(problems_to_solve) == 0:\n",
    "        logger.info(\"ğŸ‰ All problems already processed!\")\n",
    "        return existing_results\n",
    "    \n",
    "    # Initialize solver\n",
    "    api_key = os.environ.get(\"GOOGLE_API_KEY\")\n",
    "    if not api_key:\n",
    "        raise ValueError(\"GOOGLE_API_KEY environment variable not set\")\n",
    "    \n",
    "    solver = AsyncGeminiFromScratchSolver(\n",
    "        api_key=api_key,\n",
    "        generator_model=generator_model,\n",
    "        evaluator_model=evaluator_model,\n",
    "        max_iterations=max_iterations,\n",
    "        images_base_path=images_base_path,\n",
    "        labeled_samples_path=labeled_samples_path,\n",
    "        logger=logger,\n",
    "        verbose=verbose\n",
    "    )\n",
    "    \n",
    "    # Progress tracking\n",
    "    new_results = []\n",
    "    stats = {\n",
    "        'accepted': 0,\n",
    "        'rejected': 0,\n",
    "        'total_iterations': 0,\n",
    "        'total_generations': 0,\n",
    "        'confidence_sum': 0,\n",
    "        'quality_sum': 0,\n",
    "        'by_subject': {},\n",
    "        'by_category': {},\n",
    "        'by_level': {}\n",
    "    }\n",
    "    \n",
    "    # Create batches\n",
    "    batches = [problems_to_solve[i:i + batch_size] for i in range(0, len(problems_to_solve), batch_size)]\n",
    "    \n",
    "    # Use tqdm for progress bar\n",
    "    progress_bar = tqdm(batches, desc=\"Processing Batches\", \n",
    "                       disable=(console_verbosity == \"silent\"))\n",
    "    \n",
    "    batch_number = 0\n",
    "    for batch in progress_bar:\n",
    "        batch_number += 1\n",
    "        \n",
    "        # Update progress bar description\n",
    "        progress_bar.set_description(f\"Batch {batch_number}/{len(batches)} (Size: {len(batch)})\")\n",
    "        \n",
    "        logger.info(f\"\\nğŸš€ Processing batch {batch_number}/{len(batches)} with {len(batch)} problems\")\n",
    "        \n",
    "        try:\n",
    "            # Process batch asynchronously\n",
    "            batch_results = await solve_batch_async(solver, batch)\n",
    "            new_results.extend(batch_results)\n",
    "            \n",
    "            # Update statistics for this batch\n",
    "            for result in batch_results:\n",
    "                decision = result.get('final_decision', 'unknown')\n",
    "                iterations = result.get('iterations_used', 0)\n",
    "                total_generations = result.get('total_generations', 0)\n",
    "                confidence = result.get('confidence_score', 0)\n",
    "                quality = result.get('quality_score', 0)\n",
    "                \n",
    "                if decision == 'accept':\n",
    "                    stats['accepted'] += 1\n",
    "                else:\n",
    "                    stats['rejected'] += 1\n",
    "                \n",
    "                stats['total_iterations'] += iterations\n",
    "                stats['total_generations'] += total_generations\n",
    "                stats['confidence_sum'] += confidence\n",
    "                stats['quality_sum'] += quality\n",
    "                \n",
    "                # Track by categories\n",
    "                problem = result  # result contains all problem info\n",
    "                subject = problem.get('subject', 'Unknown')\n",
    "                category = problem.get('img_category', 'Unknown')\n",
    "                level = problem.get('level', 0)\n",
    "                \n",
    "                if subject not in stats['by_subject']:\n",
    "                    stats['by_subject'][subject] = {'accepted': 0, 'total': 0}\n",
    "                stats['by_subject'][subject]['total'] += 1\n",
    "                if decision == 'accept':\n",
    "                    stats['by_subject'][subject]['accepted'] += 1\n",
    "                \n",
    "                if category not in stats['by_category']:\n",
    "                    stats['by_category'][category] = {'accepted': 0, 'total': 0}\n",
    "                stats['by_category'][category]['total'] += 1\n",
    "                if decision == 'accept':\n",
    "                    stats['by_category'][category]['accepted'] += 1\n",
    "                \n",
    "                if level not in stats['by_level']:\n",
    "                    stats['by_level'][level] = {'accepted': 0, 'total': 0}\n",
    "                stats['by_level'][level]['total'] += 1\n",
    "                if decision == 'accept':\n",
    "                    stats['by_level'][level]['accepted'] += 1\n",
    "            \n",
    "            # Update progress bar postfix\n",
    "            if console_verbosity == \"minimal\":\n",
    "                current_accept_rate = stats['accepted'] / (stats['accepted'] + stats['rejected']) * 100 if (stats['accepted'] + stats['rejected']) > 0 else 0\n",
    "                avg_confidence = stats['confidence_sum'] / len(new_results) if len(new_results) > 0 else 0\n",
    "                progress_bar.set_postfix({\n",
    "                    'Accept Rate': f\"{current_accept_rate:.1f}%\",\n",
    "                    'Avg Conf': f\"{avg_confidence:.2f}\",\n",
    "                    'Completed': len(new_results)\n",
    "                })\n",
    "            \n",
    "            logger.info(f\"âœ… Batch {batch_number} completed: {len(batch_results)} results\")\n",
    "            \n",
    "            # Save progress after each batch\n",
    "            combined_results = existing_results + new_results\n",
    "            combined_results.sort(key=lambda x: x.get('index', 0))\n",
    "            \n",
    "            with open(output_file, 'w', encoding='utf-8') as f:\n",
    "                json.dump(combined_results, f, indent=2, ensure_ascii=False)\n",
    "            \n",
    "            logger.info(f\"ğŸ’¾ Progress saved: {len(combined_results)} total results\")\n",
    "            \n",
    "            # Small delay between batches to prevent rate limiting\n",
    "            await asyncio.sleep(2)\n",
    "            \n",
    "        except asyncio.CancelledError:\n",
    "            # Handle cancellation gracefully\n",
    "            logger.warning(f\"âš ï¸ Batch {batch_number} was cancelled\")\n",
    "            break\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"âŒ Batch {batch_number} failed: {e}\")\n",
    "            # Continue with next batch\n",
    "            continue\n",
    "    \n",
    "    progress_bar.close()\n",
    "    \n",
    "    # Final save and analysis\n",
    "    final_results = existing_results + new_results\n",
    "    final_results.sort(key=lambda x: x.get('index', 0))\n",
    "    \n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(final_results, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    # Analytics\n",
    "    total = len(new_results)\n",
    "    if total > 0:\n",
    "        accepted = stats['accepted']\n",
    "        rejected = stats['rejected']\n",
    "        avg_iterations = stats['total_iterations'] / total\n",
    "        avg_generations = stats['total_generations'] / total\n",
    "        avg_confidence = stats['confidence_sum'] / total\n",
    "        avg_quality = stats['quality_sum'] / total\n",
    "        \n",
    "        logger.info(f\"\\nğŸ“Š Async Gemini Physics Solver Results:\")\n",
    "        logger.info(f\"   Total Problems Processed: {total}\")\n",
    "        logger.info(f\"   Accepted: {accepted} ({accepted/total*100:.1f}%)\")\n",
    "        logger.info(f\"   Rejected (Max Iterations): {rejected} ({rejected/total*100:.1f}%)\")\n",
    "        logger.info(f\"   Average Iterations: {avg_iterations:.1f}\")\n",
    "        logger.info(f\"   Average Generations: {avg_generations:.1f}\")\n",
    "        logger.info(f\"   Average Confidence: {avg_confidence:.2f}\")\n",
    "        logger.info(f\"   Average Quality: {avg_quality:.2f}\")\n",
    "        \n",
    "        # Subject breakdown\n",
    "        logger.info(f\"\\nğŸ“‹ Performance by Subject:\")\n",
    "        for subject, data in stats['by_subject'].items():\n",
    "            rate = data['accepted'] / data['total'] * 100 if data['total'] > 0 else 0\n",
    "            logger.info(f\"   {subject}: {data['accepted']}/{data['total']} ({rate:.1f}%)\")\n",
    "        \n",
    "        # Level breakdown\n",
    "        logger.info(f\"\\nğŸ“ˆ Performance by Level:\")\n",
    "        for level in sorted(stats['by_level'].keys()):\n",
    "            data = stats['by_level'][level]\n",
    "            rate = data['accepted'] / data['total'] * 100 if data['total'] > 0 else 0\n",
    "            logger.info(f\"   Level {level}: {data['accepted']}/{data['total']} ({rate:.1f}%)\")\n",
    "    \n",
    "    logger.info(f\"\\nâœ… All results saved to: {output_file}\")\n",
    "    logger.info(f\"ğŸ“ Detailed logs saved to: {log_file}\")\n",
    "    \n",
    "    return final_results\n",
    "\n",
    "# Wrapper function to run async in Jupyter (simplified and more robust)\n",
    "def run_gemini_async_solver(problems: List[Dict[str, Any]], \n",
    "                    output_file: str = \"gemini_physics_results_async.json\",\n",
    "                    images_base_path: str = \"\",\n",
    "                    labeled_samples_path: str = \"\",\n",
    "                    max_iterations: int = 3,\n",
    "                    batch_size: int = 5):\n",
    "    \"\"\"\n",
    "    Wrapper function to run the async Gemini solver in Jupyter notebooks\n",
    "    Works with nest_asyncio for Jupyter compatibility\n",
    "    \"\"\"\n",
    "    try:\n",
    "        import nest_asyncio\n",
    "        nest_asyncio.apply()\n",
    "    except ImportError:\n",
    "        print(\"Please install nest_asyncio: pip install nest_asyncio\")\n",
    "        return None\n",
    "    \n",
    "    return asyncio.run(run_async_gemini_from_scratch_solving(\n",
    "        problems=problems,\n",
    "        images_base_path=images_base_path,\n",
    "        output_file=output_file,\n",
    "        labeled_samples_path=labeled_samples_path,\n",
    "        max_iterations=max_iterations,\n",
    "        batch_size=batch_size\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_gemini_o3():\n",
    "    \"\"\"Main function demonstrating the Gemini O3-style pipeline\"\"\"\n",
    "    \n",
    "    # Configuration\n",
    "    api_key = os.environ.get(\"GOOGLE_API_KEY\")\n",
    "    if not api_key:\n",
    "        print(\"âŒ Please set GOOGLE_API_KEY environment variable\")\n",
    "        return\n",
    "    \n",
    "    # Load your problems\n",
    "    problems = load_public_data()\n",
    "    \n",
    "    # Paths - adjust these to your setup\n",
    "\n",
    "    images_base_path=\"///mnt/c/Personal/Competitions/ICML_Track2/input/starting_kit_latest/\"\n",
    "    labeled_samples_path=\"///mnt/c/Personal/Competitions/ICML_Track2/input/starting_kit_latest/dev.json\"\n",
    "\n",
    "    # labeled_samples_path = \"path/to/your/dev.json\"  # Optional: for few-shot examples\n",
    "    \n",
    "    print(\"ğŸš€ Starting Gemini O3-Style Physics Solver\")\n",
    "    print(f\"ğŸ“Š Total problems to solve: {len(problems)}\")\n",
    "    \n",
    "    # Run the async solver\n",
    "    try:\n",
    "        results = run_gemini_async_solver(\n",
    "            problems=problems,\n",
    "            images_base_path=images_base_path,\n",
    "            output_file=\"gemini_physics_results_o3_style.json\",\n",
    "            labeled_samples_path=labeled_samples_path,  # Optional\n",
    "            max_iterations=3,  # Number of regeneration attempts\n",
    "            batch_size=25,  # Process 25 problems at a time\n",
    "        )\n",
    "        \n",
    "        print(f\"\\nğŸ‰ Completed! Processed {len(results)} problems\")\n",
    "        return results\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error during processing: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-26 00:50:08,902 - INFO - ğŸ“ Found existing results: gemini_physics_results_o3_style.json\n",
      "2025-06-26 00:50:09,068 - INFO - âœ… Loaded 1950 existing results\n",
      "2025-06-26 00:50:09,069 - INFO - ğŸ¯ Problems to solve: 50\n",
      "2025-06-26 00:50:09,069 - INFO - ğŸ“Š Total: 2000, Done: 1950, Remaining: 50\n",
      "2025-06-26 00:50:09,070 - INFO - âš¡ Batch size: 25\n",
      "2025-06-26 00:50:09,070 - INFO - ğŸ” Using labeled examples from: ///mnt/c/Personal/Competitions/ICML_Track2/input/starting_kit_latest/dev.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Starting Gemini O3-Style Physics Solver\n",
      "ğŸ“Š Total problems to solve: 2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-26 00:50:09,130 - INFO - âœ… Loaded 200 labeled examples\n",
      "Batch 1/2 (Size: 25):   0%|          | 0/2 [00:00<?, ?it/s]2025-06-26 00:50:09,163 - INFO - \n",
      "ğŸš€ Processing batch 1/2 with 25 problems\n",
      "2025-06-26 00:50:09,165 - INFO - ğŸ†• Initial generation attempt for problem 50\n",
      "2025-06-26 00:50:09,166 - INFO - âœ… Injecting 3 examples for problem 50.\n",
      "2025-06-26 00:50:09,167 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-26 00:50:09,167 - INFO - ğŸ†• Initial generation attempt for problem 51\n",
      "2025-06-26 00:50:09,169 - INFO - âœ… Injecting 3 examples for problem 51.\n",
      "2025-06-26 00:50:09,170 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-26 00:50:09,170 - INFO - ğŸ†• Initial generation attempt for problem 52\n",
      "2025-06-26 00:50:09,172 - INFO - âœ… Injecting 3 examples for problem 52.\n",
      "2025-06-26 00:50:09,173 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-26 00:50:09,173 - INFO - ğŸ†• Initial generation attempt for problem 53\n",
      "2025-06-26 00:50:09,176 - INFO - âœ… Injecting 3 examples for problem 53.\n",
      "2025-06-26 00:50:09,177 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-26 00:50:09,177 - INFO - ğŸ†• Initial generation attempt for problem 54\n",
      "2025-06-26 00:50:09,180 - INFO - âœ… Injecting 3 examples for problem 54.\n",
      "2025-06-26 00:50:09,181 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-26 00:50:09,182 - INFO - ğŸ†• Initial generation attempt for problem 55\n",
      "2025-06-26 00:50:09,184 - INFO - âœ… Injecting 3 examples for problem 55.\n",
      "2025-06-26 00:50:09,191 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-26 00:50:09,191 - INFO - ğŸ†• Initial generation attempt for problem 56\n",
      "2025-06-26 00:50:09,194 - INFO - âœ… Injecting 3 examples for problem 56.\n",
      "2025-06-26 00:50:09,195 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-26 00:50:09,195 - INFO - ğŸ†• Initial generation attempt for problem 57\n",
      "2025-06-26 00:50:09,198 - INFO - âœ… Injecting 3 examples for problem 57.\n",
      "2025-06-26 00:50:09,199 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-26 00:50:09,199 - INFO - ğŸ†• Initial generation attempt for problem 58\n",
      "2025-06-26 00:50:09,201 - INFO - âœ… Injecting 1 examples for problem 58.\n",
      "2025-06-26 00:50:09,202 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-26 00:50:09,202 - INFO - ğŸ†• Initial generation attempt for problem 59\n",
      "2025-06-26 00:50:09,204 - INFO - âœ… Injecting 3 examples for problem 59.\n",
      "2025-06-26 00:50:09,209 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-26 00:50:09,209 - INFO - ğŸ†• Initial generation attempt for problem 60\n",
      "2025-06-26 00:50:09,211 - INFO - âœ… Injecting 1 examples for problem 60.\n",
      "2025-06-26 00:50:09,213 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-26 00:50:09,213 - INFO - ğŸ†• Initial generation attempt for problem 61\n",
      "2025-06-26 00:50:09,216 - INFO - âœ… Injecting 3 examples for problem 61.\n",
      "2025-06-26 00:50:09,219 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-26 00:50:09,220 - INFO - ğŸ†• Initial generation attempt for problem 62\n",
      "2025-06-26 00:50:09,221 - INFO - âœ… Injecting 3 examples for problem 62.\n",
      "2025-06-26 00:50:09,229 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-26 00:50:09,230 - INFO - ğŸ†• Initial generation attempt for problem 63\n",
      "2025-06-26 00:50:09,233 - INFO - âœ… Injecting 3 examples for problem 63.\n",
      "2025-06-26 00:50:09,234 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-26 00:50:09,234 - INFO - ğŸ†• Initial generation attempt for problem 64\n",
      "2025-06-26 00:50:09,236 - INFO - âœ… Injecting 3 examples for problem 64.\n",
      "2025-06-26 00:50:09,237 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-26 00:50:09,238 - INFO - ğŸ†• Initial generation attempt for problem 65\n",
      "2025-06-26 00:50:09,239 - INFO - âœ… Injecting 3 examples for problem 65.\n",
      "2025-06-26 00:50:09,240 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-26 00:50:09,241 - INFO - ğŸ†• Initial generation attempt for problem 66\n",
      "2025-06-26 00:50:09,242 - INFO - âœ… Injecting 3 examples for problem 66.\n",
      "2025-06-26 00:50:09,243 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-26 00:50:09,243 - INFO - ğŸ†• Initial generation attempt for problem 67\n",
      "2025-06-26 00:50:09,246 - INFO - âœ… Injecting 3 examples for problem 67.\n",
      "2025-06-26 00:50:09,248 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-26 00:50:09,248 - INFO - ğŸ†• Initial generation attempt for problem 68\n",
      "2025-06-26 00:50:09,251 - INFO - âœ… Injecting 3 examples for problem 68.\n",
      "2025-06-26 00:50:09,259 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-26 00:50:09,259 - INFO - ğŸ†• Initial generation attempt for problem 69\n",
      "2025-06-26 00:50:09,262 - INFO - âœ… Injecting 3 examples for problem 69.\n",
      "2025-06-26 00:50:09,263 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-26 00:50:09,264 - INFO - ğŸ†• Initial generation attempt for problem 70\n",
      "2025-06-26 00:50:09,267 - INFO - âœ… Injecting 3 examples for problem 70.\n",
      "2025-06-26 00:50:09,268 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-26 00:50:09,268 - INFO - ğŸ†• Initial generation attempt for problem 71\n",
      "2025-06-26 00:50:09,271 - INFO - âœ… Injecting 1 examples for problem 71.\n",
      "2025-06-26 00:50:09,272 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-26 00:50:09,272 - INFO - ğŸ†• Initial generation attempt for problem 72\n",
      "2025-06-26 00:50:09,274 - INFO - âœ… Injecting 3 examples for problem 72.\n",
      "2025-06-26 00:50:09,275 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-26 00:50:09,275 - INFO - ğŸ†• Initial generation attempt for problem 73\n",
      "2025-06-26 00:50:09,277 - INFO - âœ… Injecting 3 examples for problem 73.\n",
      "2025-06-26 00:50:09,278 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-26 00:50:09,278 - INFO - ğŸ†• Initial generation attempt for problem 74\n",
      "2025-06-26 00:50:09,281 - INFO - âœ… Injecting 3 examples for problem 74.\n",
      "2025-06-26 00:50:51,134 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro-preview-06-05:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 00:50:51,138 - INFO - AFC remote call 1 is done.\n",
      "2025-06-26 00:50:51,138 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-26 00:50:51,140 - INFO - âœ… Generated solution for problem 60\n",
      "2025-06-26 00:51:12,487 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro-preview-06-05:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 00:51:12,496 - INFO - AFC remote call 1 is done.\n",
      "2025-06-26 00:51:12,499 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-26 00:51:12,501 - INFO - âœ… Generated solution for problem 61\n",
      "2025-06-26 00:51:16,792 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro-preview-06-05:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 00:51:16,801 - INFO - AFC remote call 1 is done.\n",
      "2025-06-26 00:51:16,802 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-26 00:51:16,803 - INFO - âœ… Generated solution for problem 50\n",
      "2025-06-26 00:51:18,875 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro-preview-06-05:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 00:51:18,883 - INFO - AFC remote call 1 is done.\n",
      "2025-06-26 00:51:18,884 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-26 00:51:18,884 - INFO - âœ… Generated solution for problem 69\n",
      "2025-06-26 00:51:20,651 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro-preview-06-05:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 00:51:20,659 - INFO - AFC remote call 1 is done.\n",
      "2025-06-26 00:51:20,660 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-26 00:51:20,668 - INFO - âœ… Generated solution for problem 58\n",
      "2025-06-26 00:51:21,701 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro-preview-06-05:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 00:51:21,714 - INFO - AFC remote call 1 is done.\n",
      "2025-06-26 00:51:21,717 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-26 00:51:21,719 - INFO - âœ… Generated solution for problem 73\n",
      "2025-06-26 00:51:30,718 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro-preview-06-05:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 00:51:30,727 - INFO - AFC remote call 1 is done.\n",
      "2025-06-26 00:51:30,727 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-26 00:51:30,728 - INFO - âœ… Generated solution for problem 72\n",
      "2025-06-26 00:51:34,510 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro-preview-06-05:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 00:51:34,512 - INFO - AFC remote call 1 is done.\n",
      "2025-06-26 00:51:34,513 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-26 00:51:34,514 - INFO - ğŸ“Š Evaluation: ACCEPT (Confidence: 1.00, Quality: 1.00, Errors: 0)\n",
      "2025-06-26 00:51:35,379 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro-preview-06-05:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 00:51:35,383 - INFO - AFC remote call 1 is done.\n",
      "2025-06-26 00:51:35,384 - INFO - ğŸ“Š Evaluation: ACCEPT (Confidence: 1.00, Quality: 1.00, Errors: 0)\n",
      "2025-06-26 00:51:38,982 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro-preview-06-05:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 00:51:38,984 - INFO - AFC remote call 1 is done.\n",
      "2025-06-26 00:51:38,985 - INFO - ğŸ“Š Evaluation: ACCEPT (Confidence: 1.00, Quality: 1.00, Errors: 0)\n",
      "2025-06-26 00:51:42,128 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro-preview-06-05:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 00:51:42,138 - INFO - AFC remote call 1 is done.\n",
      "2025-06-26 00:51:42,138 - INFO - âœ… Generated solution for problem 68\n",
      "2025-06-26 00:51:42,150 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-26 00:51:43,785 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro-preview-06-05:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 00:51:43,789 - INFO - AFC remote call 1 is done.\n",
      "2025-06-26 00:51:43,790 - INFO - ğŸ“Š Evaluation: ACCEPT (Confidence: 1.00, Quality: 1.00, Errors: 0)\n",
      "2025-06-26 00:51:46,597 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro-preview-06-05:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 00:51:46,608 - INFO - AFC remote call 1 is done.\n",
      "2025-06-26 00:51:46,609 - INFO - âœ… Generated solution for problem 57\n",
      "2025-06-26 00:51:46,610 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-26 00:51:48,389 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro-preview-06-05:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 00:51:48,393 - INFO - AFC remote call 1 is done.\n",
      "2025-06-26 00:51:48,394 - INFO - ğŸ“Š Evaluation: ACCEPT (Confidence: 1.00, Quality: 1.00, Errors: 0)\n",
      "2025-06-26 00:51:48,605 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro-preview-06-05:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 00:51:48,619 - INFO - AFC remote call 1 is done.\n",
      "2025-06-26 00:51:48,620 - INFO - âœ… Generated solution for problem 51\n",
      "2025-06-26 00:51:48,622 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-26 00:51:51,569 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro-preview-06-05:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 00:51:51,578 - INFO - AFC remote call 1 is done.\n",
      "2025-06-26 00:51:51,579 - INFO - âœ… Generated solution for problem 54\n",
      "2025-06-26 00:51:51,588 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-26 00:51:54,493 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro-preview-06-05:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 00:51:54,507 - INFO - AFC remote call 1 is done.\n",
      "2025-06-26 00:51:54,509 - INFO - âœ… Generated solution for problem 62\n",
      "2025-06-26 00:51:54,520 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-26 00:51:55,164 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro-preview-06-05:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 00:51:55,166 - INFO - AFC remote call 1 is done.\n",
      "2025-06-26 00:51:55,167 - INFO - âœ… Generated solution for problem 64\n",
      "2025-06-26 00:51:55,168 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-26 00:51:55,311 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro-preview-06-05:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 00:51:55,319 - INFO - AFC remote call 1 is done.\n",
      "2025-06-26 00:51:55,320 - INFO - âœ… Generated solution for problem 67\n",
      "2025-06-26 00:51:55,321 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-26 00:51:56,771 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro-preview-06-05:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 00:51:56,775 - INFO - AFC remote call 1 is done.\n",
      "2025-06-26 00:51:56,776 - INFO - ğŸ“Š Evaluation: ACCEPT (Confidence: 1.00, Quality: 1.00, Errors: 0)\n",
      "2025-06-26 00:51:57,774 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro-preview-06-05:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 00:51:57,786 - INFO - AFC remote call 1 is done.\n",
      "2025-06-26 00:51:57,787 - INFO - âœ… Generated solution for problem 74\n",
      "2025-06-26 00:51:57,788 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-26 00:51:59,367 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro-preview-06-05:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 00:51:59,379 - INFO - AFC remote call 1 is done.\n",
      "2025-06-26 00:51:59,382 - INFO - âœ… Generated solution for problem 59\n",
      "2025-06-26 00:51:59,389 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-26 00:52:03,343 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro-preview-06-05:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 00:52:03,345 - INFO - AFC remote call 1 is done.\n",
      "2025-06-26 00:52:03,346 - INFO - ğŸ“Š Evaluation: ACCEPT (Confidence: 1.00, Quality: 1.00, Errors: 0)\n",
      "2025-06-26 00:52:06,552 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro-preview-06-05:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 00:52:06,555 - INFO - AFC remote call 1 is done.\n",
      "2025-06-26 00:52:06,556 - INFO - âœ… Generated solution for problem 71\n",
      "2025-06-26 00:52:06,557 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-26 00:52:09,299 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro-preview-06-05:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 00:52:09,307 - INFO - AFC remote call 1 is done.\n",
      "2025-06-26 00:52:09,308 - INFO - âœ… Generated solution for problem 63\n",
      "2025-06-26 00:52:09,309 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-26 00:52:10,321 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro-preview-06-05:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 00:52:10,325 - INFO - AFC remote call 1 is done.\n",
      "2025-06-26 00:52:10,326 - INFO - ğŸ“Š Evaluation: ACCEPT (Confidence: 1.00, Quality: 1.00, Errors: 0)\n",
      "2025-06-26 00:52:11,189 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro-preview-06-05:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 00:52:11,192 - INFO - AFC remote call 1 is done.\n",
      "2025-06-26 00:52:11,193 - INFO - ğŸ“Š Evaluation: ACCEPT (Confidence: 0.95, Quality: 1.00, Errors: 0)\n",
      "2025-06-26 00:52:12,116 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro-preview-06-05:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 00:52:12,121 - INFO - AFC remote call 1 is done.\n",
      "2025-06-26 00:52:12,123 - INFO - ğŸ“Š Evaluation: ACCEPT (Confidence: 1.00, Quality: 1.00, Errors: 0)\n",
      "2025-06-26 00:52:13,006 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro-preview-06-05:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 00:52:13,010 - INFO - AFC remote call 1 is done.\n",
      "2025-06-26 00:52:13,012 - INFO - ğŸ“Š Evaluation: ACCEPT (Confidence: 0.95, Quality: 0.95, Errors: 0)\n",
      "2025-06-26 00:52:13,482 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro-preview-06-05:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 00:52:13,493 - INFO - AFC remote call 1 is done.\n",
      "2025-06-26 00:52:13,495 - INFO - âœ… Generated solution for problem 52\n",
      "2025-06-26 00:52:13,497 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-26 00:52:15,662 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro-preview-06-05:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 00:52:15,664 - INFO - AFC remote call 1 is done.\n",
      "2025-06-26 00:52:15,665 - INFO - ğŸ“Š Evaluation: ACCEPT (Confidence: 1.00, Quality: 1.00, Errors: 0)\n",
      "2025-06-26 00:52:16,570 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro-preview-06-05:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 00:52:16,574 - INFO - AFC remote call 1 is done.\n",
      "2025-06-26 00:52:16,575 - INFO - ğŸ“Š Evaluation: ACCEPT (Confidence: 1.00, Quality: 1.00, Errors: 0)\n",
      "2025-06-26 00:52:17,479 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro-preview-06-05:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 00:52:17,495 - INFO - AFC remote call 1 is done.\n",
      "2025-06-26 00:52:17,500 - INFO - ğŸ“Š Evaluation: ACCEPT (Confidence: 1.00, Quality: 1.00, Errors: 0)\n",
      "2025-06-26 00:52:23,671 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro-preview-06-05:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 00:52:23,676 - INFO - AFC remote call 1 is done.\n",
      "2025-06-26 00:52:23,678 - INFO - âœ… Generated solution for problem 65\n",
      "2025-06-26 00:52:23,679 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-26 00:52:25,024 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro-preview-06-05:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 00:52:25,029 - INFO - AFC remote call 1 is done.\n",
      "2025-06-26 00:52:25,031 - INFO - ğŸ“Š Evaluation: ACCEPT (Confidence: 0.95, Quality: 1.00, Errors: 0)\n",
      "2025-06-26 00:52:26,250 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro-preview-06-05:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 00:52:26,252 - INFO - AFC remote call 1 is done.\n",
      "2025-06-26 00:52:26,253 - INFO - ğŸ“Š Evaluation: ACCEPT (Confidence: 1.00, Quality: 1.00, Errors: 0)\n",
      "2025-06-26 00:52:34,317 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro-preview-06-05:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 00:52:34,321 - INFO - AFC remote call 1 is done.\n",
      "2025-06-26 00:52:34,322 - INFO - ğŸ“Š Evaluation: ACCEPT (Confidence: 0.95, Quality: 0.90, Errors: 0)\n",
      "2025-06-26 00:52:34,961 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro-preview-06-05:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 00:52:34,970 - INFO - AFC remote call 1 is done.\n",
      "2025-06-26 00:52:34,972 - INFO - ğŸ“Š Evaluation: ACCEPT (Confidence: 1.00, Quality: 1.00, Errors: 0)\n",
      "2025-06-26 00:52:42,924 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro-preview-06-05:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 00:52:42,936 - INFO - AFC remote call 1 is done.\n",
      "2025-06-26 00:52:42,938 - INFO - âœ… Generated solution for problem 56\n",
      "2025-06-26 00:52:42,939 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-26 00:52:44,159 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro-preview-06-05:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 00:52:44,172 - INFO - AFC remote call 1 is done.\n",
      "2025-06-26 00:52:44,174 - INFO - âœ… Generated solution for problem 53\n",
      "2025-06-26 00:52:44,175 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-26 00:52:50,036 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro-preview-06-05:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 00:52:50,040 - INFO - AFC remote call 1 is done.\n",
      "2025-06-26 00:52:50,041 - INFO - ğŸ“Š Evaluation: ACCEPT (Confidence: 0.95, Quality: 0.95, Errors: 0)\n",
      "2025-06-26 00:53:25,624 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro-preview-06-05:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 00:53:25,638 - INFO - AFC remote call 1 is done.\n",
      "2025-06-26 00:53:25,640 - INFO - âœ… Generated solution for problem 55\n",
      "2025-06-26 00:53:25,649 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-26 00:53:31,548 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro-preview-06-05:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 00:53:31,557 - INFO - AFC remote call 1 is done.\n",
      "2025-06-26 00:53:31,559 - INFO - âœ… Generated solution for problem 66\n",
      "2025-06-26 00:53:31,560 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-26 00:53:43,363 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro-preview-06-05:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 00:53:43,370 - INFO - AFC remote call 1 is done.\n",
      "2025-06-26 00:53:43,371 - INFO - ğŸ“Š Evaluation: ACCEPT (Confidence: 1.00, Quality: 1.00, Errors: 0)\n",
      "2025-06-26 00:53:50,974 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro-preview-06-05:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 00:53:50,983 - INFO - AFC remote call 1 is done.\n",
      "2025-06-26 00:53:50,986 - INFO - ğŸ“Š Evaluation: ACCEPT (Confidence: 1.00, Quality: 1.00, Errors: 0)\n",
      "2025-06-26 00:54:19,231 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro-preview-06-05:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 00:54:19,233 - INFO - AFC remote call 1 is done.\n",
      "2025-06-26 00:54:19,234 - INFO - ğŸ“Š Evaluation: ACCEPT (Confidence: 1.00, Quality: 1.00, Errors: 0)\n",
      "2025-06-26 00:54:23,551 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro-preview-06-05:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 00:54:23,556 - INFO - AFC remote call 1 is done.\n",
      "2025-06-26 00:54:23,559 - INFO - ğŸ“Š Evaluation: REJECT (Confidence: 1.00, Quality: 0.30, Errors: 3)\n",
      "2025-06-26 00:54:23,561 - INFO - ğŸ”„ Regeneration attempt 2 with feedback for problem 56\n",
      "2025-06-26 00:54:23,562 - INFO - âœ… Injecting 3 examples for problem 56.\n",
      "2025-06-26 00:54:23,566 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-26 00:55:13,004 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro-preview-06-05:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 00:55:13,007 - INFO - AFC remote call 1 is done.\n",
      "2025-06-26 00:55:13,008 - WARNING - Failed to parse structured output: Expecting ',' delimiter: line 3 column 17331 (char 17356)\n",
      "2025-06-26 00:55:13,008 - INFO - ğŸ“Š Evaluation: REJECT (Confidence: 0.50, Quality: 0.50, Errors: 0)\n",
      "2025-06-26 00:55:13,009 - INFO - ğŸ”„ Regeneration attempt 2 with feedback for problem 65\n",
      "2025-06-26 00:55:13,009 - INFO - âœ… Injecting 3 examples for problem 65.\n",
      "2025-06-26 00:55:13,010 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-26 00:55:17,821 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro-preview-06-05:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 00:55:17,835 - INFO - AFC remote call 1 is done.\n",
      "2025-06-26 00:55:17,837 - INFO - âœ… Generated solution for problem 70\n",
      "2025-06-26 00:55:17,839 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-26 00:55:54,455 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro-preview-06-05:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 00:55:54,457 - INFO - AFC remote call 1 is done.\n",
      "2025-06-26 00:55:54,458 - INFO - ğŸ“Š Evaluation: REJECT (Confidence: 0.20, Quality: 0.30, Errors: 2)\n",
      "2025-06-26 00:55:54,459 - INFO - ğŸ”„ Regeneration attempt 2 with feedback for problem 70\n",
      "2025-06-26 00:55:54,459 - INFO - âœ… Injecting 3 examples for problem 70.\n",
      "2025-06-26 00:55:54,460 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-26 00:56:05,183 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro-preview-06-05:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 00:56:05,186 - INFO - AFC remote call 1 is done.\n",
      "2025-06-26 00:56:05,187 - INFO - âœ… Regenerated solution addressing 3 previous errors\n",
      "2025-06-26 00:56:05,188 - INFO -    Previous confidence: 1.00\n",
      "2025-06-26 00:56:05,189 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-26 00:56:35,544 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro-preview-06-05:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 00:56:35,557 - INFO - AFC remote call 1 is done.\n",
      "2025-06-26 00:56:35,560 - INFO - âœ… Regenerated solution addressing 0 previous errors\n",
      "2025-06-26 00:56:35,561 - INFO -    Previous confidence: 0.50\n",
      "2025-06-26 00:56:35,564 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-26 00:57:10,531 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro-preview-06-05:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 00:57:10,533 - INFO - AFC remote call 1 is done.\n",
      "2025-06-26 00:57:10,534 - INFO - ğŸ“Š Evaluation: ACCEPT (Confidence: 1.00, Quality: 1.00, Errors: 0)\n",
      "2025-06-26 00:57:12,999 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro-preview-06-05:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 00:57:13,013 - INFO - AFC remote call 1 is done.\n",
      "2025-06-26 00:57:13,014 - INFO - âœ… Regenerated solution addressing 2 previous errors\n",
      "2025-06-26 00:57:13,015 - INFO -    Previous confidence: 0.20\n",
      "2025-06-26 00:57:13,016 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-26 00:57:31,337 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro-preview-06-05:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 00:57:31,347 - INFO - AFC remote call 1 is done.\n",
      "2025-06-26 00:57:31,352 - INFO - ğŸ“Š Evaluation: ACCEPT (Confidence: 0.95, Quality: 0.95, Errors: 0)\n",
      "2025-06-26 00:57:35,057 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro-preview-06-05:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 00:57:35,064 - INFO - AFC remote call 1 is done.\n",
      "2025-06-26 00:57:35,068 - INFO - ğŸ“Š Evaluation: ACCEPT (Confidence: 1.00, Quality: 1.00, Errors: 0)\n",
      "Batch 1/2 (Size: 25):   0%|          | 0/2 [07:25<?, ?it/s, Accept Rate=100.0%, Avg Conf=0.99, Completed=25]2025-06-26 00:57:35,077 - INFO - âœ… Batch 1 completed: 25 results\n",
      "2025-06-26 00:57:35,333 - INFO - ğŸ’¾ Progress saved: 1975 total results\n",
      "Batch 2/2 (Size: 25):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [07:28<07:28, 448.17s/it, Accept Rate=100.0%, Avg Conf=0.99, Completed=25]2025-06-26 00:57:37,337 - INFO - \n",
      "ğŸš€ Processing batch 2/2 with 25 problems\n",
      "2025-06-26 00:57:37,338 - INFO - ğŸ†• Initial generation attempt for problem 100\n",
      "2025-06-26 00:57:37,339 - INFO - âœ… Injecting 3 examples for problem 100.\n",
      "2025-06-26 00:57:37,340 - INFO - ğŸ†• Initial generation attempt for problem 101\n",
      "2025-06-26 00:57:37,340 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-26 00:57:37,340 - INFO - âœ… Injecting 3 examples for problem 101.\n",
      "2025-06-26 00:57:37,342 - INFO - ğŸ†• Initial generation attempt for problem 102\n",
      "2025-06-26 00:57:37,343 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-26 00:57:37,343 - INFO - âœ… Injecting 3 examples for problem 102.\n",
      "2025-06-26 00:57:37,347 - INFO - ğŸ†• Initial generation attempt for problem 103\n",
      "2025-06-26 00:57:37,347 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-26 00:57:37,349 - INFO - âœ… Injecting 3 examples for problem 103.\n",
      "2025-06-26 00:57:37,352 - INFO - ğŸ†• Initial generation attempt for problem 104\n",
      "2025-06-26 00:57:37,352 - INFO - âœ… Injecting 3 examples for problem 104.\n",
      "2025-06-26 00:57:37,353 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-26 00:57:37,354 - INFO - ğŸ†• Initial generation attempt for problem 105\n",
      "2025-06-26 00:57:37,354 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-26 00:57:37,358 - INFO - âœ… Injecting 2 examples for problem 105.\n",
      "2025-06-26 00:57:37,360 - INFO - ğŸ†• Initial generation attempt for problem 106\n",
      "2025-06-26 00:57:37,360 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-26 00:57:37,361 - INFO - âœ… Injecting 3 examples for problem 106.\n",
      "2025-06-26 00:57:37,382 - INFO - ğŸ†• Initial generation attempt for problem 107\n",
      "2025-06-26 00:57:37,382 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-26 00:57:37,383 - INFO - âœ… Injecting 3 examples for problem 107.\n",
      "2025-06-26 00:57:37,385 - INFO - ğŸ†• Initial generation attempt for problem 108\n",
      "2025-06-26 00:57:37,385 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-26 00:57:37,386 - INFO - âœ… Injecting 3 examples for problem 108.\n",
      "2025-06-26 00:57:37,388 - INFO - ğŸ†• Initial generation attempt for problem 109\n",
      "2025-06-26 00:57:37,388 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-26 00:57:37,388 - INFO - âœ… Injecting 3 examples for problem 109.\n",
      "2025-06-26 00:57:37,390 - INFO - ğŸ†• Initial generation attempt for problem 110\n",
      "2025-06-26 00:57:37,391 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-26 00:57:37,391 - INFO - âœ… Injecting 3 examples for problem 110.\n",
      "2025-06-26 00:57:37,395 - INFO - ğŸ†• Initial generation attempt for problem 111\n",
      "2025-06-26 00:57:37,395 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-26 00:57:37,397 - INFO - âœ… Injecting 3 examples for problem 111.\n",
      "2025-06-26 00:57:37,405 - INFO - ğŸ†• Initial generation attempt for problem 112\n",
      "2025-06-26 00:57:37,405 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-26 00:57:37,406 - INFO - âœ… Injecting 3 examples for problem 112.\n",
      "2025-06-26 00:57:37,408 - INFO - ğŸ†• Initial generation attempt for problem 113\n",
      "2025-06-26 00:57:37,409 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-26 00:57:37,410 - INFO - âœ… Injecting 3 examples for problem 113.\n",
      "2025-06-26 00:57:37,412 - INFO - ğŸ†• Initial generation attempt for problem 114\n",
      "2025-06-26 00:57:37,412 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-26 00:57:37,414 - INFO - âœ… Injecting 3 examples for problem 114.\n",
      "2025-06-26 00:57:37,418 - INFO - ğŸ†• Initial generation attempt for problem 115\n",
      "2025-06-26 00:57:37,418 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-26 00:57:37,419 - INFO - âœ… Injecting 3 examples for problem 115.\n",
      "2025-06-26 00:57:37,422 - INFO - ğŸ†• Initial generation attempt for problem 116\n",
      "2025-06-26 00:57:37,422 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-26 00:57:37,423 - INFO - âœ… Injecting 3 examples for problem 116.\n",
      "2025-06-26 00:57:37,426 - INFO - ğŸ†• Initial generation attempt for problem 117\n",
      "2025-06-26 00:57:37,426 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-26 00:57:37,427 - INFO - âœ… Injecting 3 examples for problem 117.\n",
      "2025-06-26 00:57:37,438 - INFO - ğŸ†• Initial generation attempt for problem 118\n",
      "2025-06-26 00:57:37,438 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-26 00:57:37,439 - INFO - âœ… Injecting 3 examples for problem 118.\n",
      "2025-06-26 00:57:37,441 - INFO - ğŸ†• Initial generation attempt for problem 119\n",
      "2025-06-26 00:57:37,442 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-26 00:57:37,442 - INFO - âœ… Injecting 3 examples for problem 119.\n",
      "2025-06-26 00:57:37,444 - INFO - ğŸ†• Initial generation attempt for problem 120\n",
      "2025-06-26 00:57:37,445 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-26 00:57:37,446 - INFO - âœ… Injecting 3 examples for problem 120.\n",
      "2025-06-26 00:57:37,458 - INFO - ğŸ†• Initial generation attempt for problem 121\n",
      "2025-06-26 00:57:37,458 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-26 00:57:37,458 - INFO - âœ… Injecting 3 examples for problem 121.\n",
      "2025-06-26 00:57:37,461 - INFO - ğŸ†• Initial generation attempt for problem 122\n",
      "2025-06-26 00:57:37,461 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-26 00:57:37,462 - INFO - âœ… Injecting 3 examples for problem 122.\n",
      "2025-06-26 00:57:37,464 - INFO - ğŸ†• Initial generation attempt for problem 123\n",
      "2025-06-26 00:57:37,464 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-26 00:57:37,465 - INFO - âœ… Injecting 3 examples for problem 123.\n",
      "2025-06-26 00:57:37,468 - INFO - ğŸ†• Initial generation attempt for problem 124\n",
      "2025-06-26 00:57:37,468 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-26 00:57:37,469 - INFO - âœ… Injecting 3 examples for problem 124.\n",
      "2025-06-26 00:57:37,841 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro-preview-06-05:generateContent \"HTTP/1.1 503 Service Unavailable\"\n",
      "2025-06-26 00:57:37,843 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-26 00:57:37,843 - ERROR - Generation failed: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}\n",
      "2025-06-26 00:57:37,845 - INFO - âœ… Generated solution for problem 100\n",
      "2025-06-26 00:57:38,472 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro-preview-06-05:generateContent \"HTTP/1.1 503 Service Unavailable\"\n",
      "2025-06-26 00:57:38,474 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-26 00:57:38,475 - ERROR - Generation failed: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}\n",
      "2025-06-26 00:57:38,483 - INFO - âœ… Generated solution for problem 117\n",
      "2025-06-26 00:58:11,215 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro-preview-06-05:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 00:58:11,220 - INFO - AFC remote call 1 is done.\n",
      "2025-06-26 00:58:11,222 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-26 00:58:11,222 - INFO - âœ… Generated solution for problem 124\n",
      "2025-06-26 00:58:19,816 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro-preview-06-05:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 00:58:19,819 - INFO - AFC remote call 1 is done.\n",
      "2025-06-26 00:58:19,820 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-26 00:58:19,823 - INFO - ğŸ“Š Evaluation: REJECT (Confidence: 0.00, Quality: 0.00, Errors: 0)\n",
      "2025-06-26 00:58:19,824 - INFO - ğŸ”„ Regeneration attempt 2 with feedback for problem 117\n",
      "2025-06-26 00:58:19,825 - INFO - âœ… Injecting 3 examples for problem 117.\n",
      "2025-06-26 00:58:27,053 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro-preview-06-05:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 00:58:27,055 - INFO - AFC remote call 1 is done.\n",
      "2025-06-26 00:58:27,056 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-26 00:58:27,057 - INFO - âœ… Generated solution for problem 120\n",
      "2025-06-26 00:58:34,180 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro-preview-06-05:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 00:58:34,186 - INFO - AFC remote call 1 is done.\n",
      "2025-06-26 00:58:34,188 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-26 00:58:34,190 - INFO - ğŸ“Š Evaluation: ACCEPT (Confidence: 1.00, Quality: 1.00, Errors: 0)\n",
      "2025-06-26 00:58:36,428 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro-preview-06-05:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 00:58:36,436 - INFO - AFC remote call 1 is done.\n",
      "2025-06-26 00:58:36,437 - INFO - âœ… Generated solution for problem 114\n",
      "2025-06-26 00:58:36,438 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-26 00:58:39,529 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro-preview-06-05:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 00:58:39,542 - INFO - AFC remote call 1 is done.\n",
      "2025-06-26 00:58:39,543 - INFO - âœ… Generated solution for problem 107\n",
      "2025-06-26 00:58:39,545 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-26 00:58:43,736 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro-preview-06-05:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 00:58:43,738 - INFO - AFC remote call 1 is done.\n",
      "2025-06-26 00:58:43,739 - INFO - âœ… Generated solution for problem 115\n",
      "2025-06-26 00:58:43,740 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-26 00:58:47,146 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro-preview-06-05:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 00:58:47,154 - INFO - AFC remote call 1 is done.\n",
      "2025-06-26 00:58:47,155 - INFO - âœ… Generated solution for problem 123\n",
      "2025-06-26 00:58:47,158 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-26 00:58:48,893 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro-preview-06-05:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 00:58:48,901 - INFO - AFC remote call 1 is done.\n",
      "2025-06-26 00:58:48,903 - INFO - âœ… Generated solution for problem 122\n",
      "2025-06-26 00:58:48,904 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-26 00:58:50,870 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro-preview-06-05:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 00:58:50,876 - INFO - AFC remote call 1 is done.\n",
      "2025-06-26 00:58:50,877 - INFO - âœ… Generated solution for problem 112\n",
      "2025-06-26 00:58:50,884 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-26 00:58:52,681 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro-preview-06-05:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 00:58:52,688 - INFO - AFC remote call 1 is done.\n",
      "2025-06-26 00:58:52,689 - INFO - âœ… Generated solution for problem 108\n",
      "2025-06-26 00:58:52,690 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-26 00:58:54,336 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro-preview-06-05:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 00:58:54,341 - INFO - AFC remote call 1 is done.\n",
      "2025-06-26 00:58:54,343 - INFO - ğŸ“Š Evaluation: ACCEPT (Confidence: 1.00, Quality: 1.00, Errors: 0)\n",
      "2025-06-26 00:58:54,537 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro-preview-06-05:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 00:58:54,539 - INFO - AFC remote call 1 is done.\n",
      "2025-06-26 00:58:54,541 - INFO - âœ… Generated solution for problem 109\n",
      "2025-06-26 00:58:54,542 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-26 00:58:57,707 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro-preview-06-05:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 00:58:57,709 - INFO - AFC remote call 1 is done.\n",
      "2025-06-26 00:58:57,710 - INFO - ğŸ“Š Evaluation: ACCEPT (Confidence: 1.00, Quality: 1.00, Errors: 0)\n",
      "2025-06-26 00:58:58,836 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro-preview-06-05:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 00:58:58,838 - INFO - AFC remote call 1 is done.\n",
      "2025-06-26 00:58:58,839 - INFO - ğŸ“Š Evaluation: ACCEPT (Confidence: 1.00, Quality: 1.00, Errors: 0)\n",
      "2025-06-26 00:59:07,907 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro-preview-06-05:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 00:59:07,922 - INFO - AFC remote call 1 is done.\n",
      "2025-06-26 00:59:07,924 - INFO - âœ… Generated solution for problem 103\n",
      "2025-06-26 00:59:07,925 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-26 00:59:10,400 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro-preview-06-05:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 00:59:10,410 - INFO - AFC remote call 1 is done.\n",
      "2025-06-26 00:59:10,412 - INFO - âœ… Generated solution for problem 111\n",
      "2025-06-26 00:59:10,418 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-26 00:59:11,043 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro-preview-06-05:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 00:59:11,051 - INFO - AFC remote call 1 is done.\n",
      "2025-06-26 00:59:11,052 - INFO - âœ… Generated solution for problem 118\n",
      "2025-06-26 00:59:11,054 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-26 00:59:12,292 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro-preview-06-05:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 00:59:12,301 - INFO - AFC remote call 1 is done.\n",
      "2025-06-26 00:59:12,302 - INFO - âœ… Generated solution for problem 110\n",
      "2025-06-26 00:59:12,303 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-26 00:59:12,321 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro-preview-06-05:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 00:59:12,323 - INFO - AFC remote call 1 is done.\n",
      "2025-06-26 00:59:12,324 - INFO - ğŸ“Š Evaluation: ACCEPT (Confidence: 1.00, Quality: 1.00, Errors: 0)\n",
      "2025-06-26 00:59:12,627 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro-preview-06-05:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 00:59:12,633 - INFO - AFC remote call 1 is done.\n",
      "2025-06-26 00:59:12,634 - INFO - ğŸ“Š Evaluation: ACCEPT (Confidence: 1.00, Quality: 1.00, Errors: 0)\n",
      "2025-06-26 00:59:14,707 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro-preview-06-05:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 00:59:14,711 - INFO - AFC remote call 1 is done.\n",
      "2025-06-26 00:59:14,713 - INFO - ğŸ“Š Evaluation: ACCEPT (Confidence: 1.00, Quality: 1.00, Errors: 0)\n",
      "2025-06-26 00:59:19,401 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro-preview-06-05:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 00:59:19,416 - INFO - AFC remote call 1 is done.\n",
      "2025-06-26 00:59:19,418 - INFO - âœ… Generated solution for problem 105\n",
      "2025-06-26 00:59:19,419 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-26 00:59:20,118 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro-preview-06-05:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 00:59:20,122 - INFO - AFC remote call 1 is done.\n",
      "2025-06-26 00:59:20,123 - INFO - ğŸ“Š Evaluation: ACCEPT (Confidence: 1.00, Quality: 1.00, Errors: 0)\n",
      "2025-06-26 00:59:24,327 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro-preview-06-05:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 00:59:24,340 - INFO - AFC remote call 1 is done.\n",
      "2025-06-26 00:59:24,342 - INFO - âœ… Generated solution for problem 113\n",
      "2025-06-26 00:59:24,343 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-26 00:59:25,438 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro-preview-06-05:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 00:59:25,441 - INFO - AFC remote call 1 is done.\n",
      "2025-06-26 00:59:25,443 - INFO - ğŸ“Š Evaluation: ACCEPT (Confidence: 0.95, Quality: 1.00, Errors: 0)\n",
      "2025-06-26 00:59:27,317 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro-preview-06-05:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 00:59:27,323 - INFO - AFC remote call 1 is done.\n",
      "2025-06-26 00:59:27,325 - INFO - ğŸ“Š Evaluation: ACCEPT (Confidence: 0.95, Quality: 1.00, Errors: 0)\n",
      "2025-06-26 00:59:29,490 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro-preview-06-05:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 00:59:29,497 - INFO - AFC remote call 1 is done.\n",
      "2025-06-26 00:59:29,500 - INFO - ğŸ“Š Evaluation: ACCEPT (Confidence: 1.00, Quality: 1.00, Errors: 0)\n",
      "2025-06-26 00:59:32,821 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro-preview-06-05:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 00:59:32,823 - INFO - AFC remote call 1 is done.\n",
      "2025-06-26 00:59:32,824 - INFO - ğŸ“Š Evaluation: ACCEPT (Confidence: 1.00, Quality: 1.00, Errors: 0)\n",
      "2025-06-26 00:59:36,180 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro-preview-06-05:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 00:59:36,185 - INFO - AFC remote call 1 is done.\n",
      "2025-06-26 00:59:36,186 - INFO - ğŸ“Š Evaluation: ACCEPT (Confidence: 1.00, Quality: 1.00, Errors: 0)\n",
      "2025-06-26 00:59:41,742 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro-preview-06-05:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 00:59:41,746 - INFO - AFC remote call 1 is done.\n",
      "2025-06-26 00:59:41,748 - INFO - ğŸ“Š Evaluation: ACCEPT (Confidence: 1.00, Quality: 1.00, Errors: 0)\n",
      "2025-06-26 00:59:44,789 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro-preview-06-05:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 00:59:44,791 - INFO - AFC remote call 1 is done.\n",
      "2025-06-26 00:59:44,792 - INFO - ğŸ“Š Evaluation: ACCEPT (Confidence: 1.00, Quality: 1.00, Errors: 0)\n",
      "2025-06-26 00:59:46,901 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro-preview-06-05:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 00:59:46,912 - INFO - AFC remote call 1 is done.\n",
      "2025-06-26 00:59:46,913 - INFO - âœ… Generated solution for problem 106\n",
      "2025-06-26 00:59:46,919 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-26 00:59:47,723 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro-preview-06-05:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 00:59:47,734 - INFO - AFC remote call 1 is done.\n",
      "2025-06-26 00:59:47,736 - INFO - âœ… Generated solution for problem 119\n",
      "2025-06-26 00:59:47,738 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-26 00:59:50,163 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro-preview-06-05:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 00:59:50,173 - INFO - AFC remote call 1 is done.\n",
      "2025-06-26 00:59:50,174 - INFO - âœ… Generated solution for problem 102\n",
      "2025-06-26 00:59:50,175 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-26 00:59:52,383 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro-preview-06-05:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 00:59:52,396 - INFO - AFC remote call 1 is done.\n",
      "2025-06-26 00:59:52,397 - INFO - âœ… Generated solution for problem 101\n",
      "2025-06-26 00:59:52,398 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-26 00:59:52,682 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro-preview-06-05:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 00:59:52,684 - INFO - AFC remote call 1 is done.\n",
      "2025-06-26 00:59:52,685 - INFO - âœ… Generated solution for problem 116\n",
      "2025-06-26 00:59:52,686 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-26 01:00:00,434 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro-preview-06-05:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 01:00:00,444 - INFO - AFC remote call 1 is done.\n",
      "2025-06-26 01:00:00,445 - INFO - âœ… Generated solution for problem 121\n",
      "2025-06-26 01:00:00,446 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-26 01:00:17,482 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro-preview-06-05:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 01:00:17,486 - INFO - AFC remote call 1 is done.\n",
      "2025-06-26 01:00:17,488 - INFO - ğŸ“Š Evaluation: ACCEPT (Confidence: 1.00, Quality: 1.00, Errors: 0)\n",
      "2025-06-26 01:00:19,659 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro-preview-06-05:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 01:00:19,665 - INFO - AFC remote call 1 is done.\n",
      "2025-06-26 01:00:19,667 - INFO - ğŸ“Š Evaluation: ACCEPT (Confidence: 1.00, Quality: 1.00, Errors: 0)\n",
      "2025-06-26 01:00:23,953 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro-preview-06-05:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 01:00:23,955 - INFO - AFC remote call 1 is done.\n",
      "2025-06-26 01:00:23,955 - INFO - ğŸ“Š Evaluation: REJECT (Confidence: 0.00, Quality: 0.00, Errors: 0)\n",
      "2025-06-26 01:00:23,956 - INFO - ğŸ”„ Regeneration attempt 2 with feedback for problem 100\n",
      "2025-06-26 01:00:23,957 - INFO - âœ… Injecting 3 examples for problem 100.\n",
      "2025-06-26 01:00:23,959 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-26 01:00:27,186 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro-preview-06-05:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 01:00:27,188 - INFO - AFC remote call 1 is done.\n",
      "2025-06-26 01:00:27,190 - INFO - ğŸ“Š Evaluation: ACCEPT (Confidence: 0.95, Quality: 0.95, Errors: 0)\n",
      "2025-06-26 01:00:33,460 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro-preview-06-05:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 01:00:33,463 - INFO - AFC remote call 1 is done.\n",
      "2025-06-26 01:00:33,464 - INFO - ğŸ“Š Evaluation: ACCEPT (Confidence: 0.95, Quality: 0.95, Errors: 0)\n",
      "2025-06-26 01:00:42,831 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro-preview-06-05:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 01:00:42,835 - INFO - AFC remote call 1 is done.\n",
      "2025-06-26 01:00:42,836 - INFO - âœ… Regenerated solution addressing 0 previous errors\n",
      "2025-06-26 01:00:42,836 - INFO -    Previous confidence: 0.00\n",
      "2025-06-26 01:00:42,842 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-26 01:00:53,969 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro-preview-06-05:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 01:00:53,972 - INFO - AFC remote call 1 is done.\n",
      "2025-06-26 01:00:53,974 - INFO - ğŸ“Š Evaluation: ACCEPT (Confidence: 0.95, Quality: 0.95, Errors: 0)\n",
      "2025-06-26 01:01:05,596 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro-preview-06-05:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 01:01:05,602 - INFO - AFC remote call 1 is done.\n",
      "2025-06-26 01:01:05,604 - INFO - ğŸ“Š Evaluation: ACCEPT (Confidence: 1.00, Quality: 1.00, Errors: 0)\n",
      "2025-06-26 01:01:11,902 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro-preview-06-05:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 01:01:11,906 - INFO - AFC remote call 1 is done.\n",
      "2025-06-26 01:01:11,908 - INFO - ğŸ“Š Evaluation: ACCEPT (Confidence: 0.95, Quality: 0.95, Errors: 0)\n",
      "2025-06-26 01:02:08,187 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro-preview-06-05:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 01:02:08,196 - INFO - AFC remote call 1 is done.\n",
      "2025-06-26 01:02:08,201 - WARNING - Failed to parse structured output: Expecting ',' delimiter: line 3 column 18419 (char 18444)\n",
      "2025-06-26 01:02:08,202 - INFO - ğŸ“Š Evaluation: REJECT (Confidence: 0.50, Quality: 0.50, Errors: 0)\n",
      "2025-06-26 01:02:08,203 - INFO - ğŸ”„ Regeneration attempt 2 with feedback for problem 105\n",
      "2025-06-26 01:02:08,205 - INFO - âœ… Injecting 2 examples for problem 105.\n",
      "2025-06-26 01:02:08,205 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-26 01:02:51,380 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro-preview-06-05:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 01:02:51,388 - INFO - AFC remote call 1 is done.\n",
      "2025-06-26 01:02:51,389 - INFO - âœ… Generated solution for problem 104\n",
      "2025-06-26 01:02:51,390 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-26 01:03:26,164 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro-preview-06-05:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 01:03:26,175 - INFO - AFC remote call 1 is done.\n",
      "2025-06-26 01:03:26,176 - INFO - âœ… Regenerated solution addressing 0 previous errors\n",
      "2025-06-26 01:03:26,177 - INFO -    Previous confidence: 0.00\n",
      "2025-06-26 01:03:26,180 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-26 01:03:38,407 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro-preview-06-05:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 01:03:38,417 - INFO - AFC remote call 1 is done.\n",
      "2025-06-26 01:03:38,419 - INFO - âœ… Regenerated solution addressing 0 previous errors\n",
      "2025-06-26 01:03:38,420 - INFO -    Previous confidence: 0.50\n",
      "2025-06-26 01:03:38,421 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-26 01:03:47,287 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro-preview-06-05:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 01:03:47,291 - INFO - AFC remote call 1 is done.\n",
      "2025-06-26 01:03:47,292 - INFO - ğŸ“Š Evaluation: REJECT (Confidence: 0.95, Quality: 0.95, Errors: 1)\n",
      "2025-06-26 01:03:47,296 - INFO - ğŸ”„ Regeneration attempt 2 with feedback for problem 104\n",
      "2025-06-26 01:03:47,298 - INFO - âœ… Injecting 3 examples for problem 104.\n",
      "2025-06-26 01:03:47,301 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-26 01:03:52,916 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro-preview-06-05:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 01:03:52,918 - INFO - AFC remote call 1 is done.\n",
      "2025-06-26 01:03:52,919 - INFO - ğŸ“Š Evaluation: ACCEPT (Confidence: 0.95, Quality: 0.95, Errors: 0)\n",
      "2025-06-26 01:04:04,978 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro-preview-06-05:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 01:04:04,983 - INFO - AFC remote call 1 is done.\n",
      "2025-06-26 01:04:04,984 - INFO - ğŸ“Š Evaluation: ACCEPT (Confidence: 1.00, Quality: 1.00, Errors: 0)\n",
      "2025-06-26 01:05:45,538 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro-preview-06-05:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 01:05:45,550 - INFO - AFC remote call 1 is done.\n",
      "2025-06-26 01:05:45,551 - INFO - âœ… Regenerated solution addressing 1 previous errors\n",
      "2025-06-26 01:05:45,552 - INFO -    Previous confidence: 0.95\n",
      "2025-06-26 01:05:45,553 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-26 01:06:22,523 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro-preview-06-05:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 01:06:22,531 - INFO - AFC remote call 1 is done.\n",
      "2025-06-26 01:06:22,533 - INFO - ğŸ“Š Evaluation: REJECT (Confidence: 0.55, Quality: 0.50, Errors: 1)\n",
      "2025-06-26 01:06:22,534 - INFO - ğŸ”„ Regeneration attempt 3 with feedback for problem 104\n",
      "2025-06-26 01:06:22,535 - INFO - âœ… Injecting 3 examples for problem 104.\n",
      "2025-06-26 01:06:22,536 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-26 01:08:03,204 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro-preview-06-05:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 01:08:03,217 - INFO - AFC remote call 1 is done.\n",
      "2025-06-26 01:08:03,218 - INFO - âœ… Regenerated solution addressing 1 previous errors\n",
      "2025-06-26 01:08:03,218 - INFO -    Previous confidence: 0.55\n",
      "2025-06-26 01:08:03,219 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-06-26 01:08:39,239 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro-preview-06-05:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 01:08:39,246 - INFO - AFC remote call 1 is done.\n",
      "2025-06-26 01:08:39,248 - INFO - ğŸ“Š Evaluation: ACCEPT (Confidence: 0.95, Quality: 0.95, Errors: 0)\n",
      "2025-06-26 01:08:39,249 - WARNING - âš ï¸ Max iterations (3) reached for problem 104\n",
      "Batch 2/2 (Size: 25):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [18:30<07:28, 448.17s/it, Accept Rate=100.0%, Avg Conf=0.99, Completed=50]2025-06-26 01:08:39,252 - INFO - âœ… Batch 2 completed: 25 results\n",
      "2025-06-26 01:08:39,511 - INFO - ğŸ’¾ Progress saved: 2000 total results\n",
      "Batch 2/2 (Size: 25): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [18:32<00:00, 556.18s/it, Accept Rate=100.0%, Avg Conf=0.99, Completed=50]\n",
      "2025-06-26 01:08:41,772 - INFO - \n",
      "ğŸ“Š Async Gemini Physics Solver Results:\n",
      "2025-06-26 01:08:41,773 - INFO -    Total Problems Processed: 50\n",
      "2025-06-26 01:08:41,773 - INFO -    Accepted: 50 (100.0%)\n",
      "2025-06-26 01:08:41,774 - INFO -    Rejected (Max Iterations): 0 (0.0%)\n",
      "2025-06-26 01:08:41,774 - INFO -    Average Iterations: 1.0\n",
      "2025-06-26 01:08:41,775 - INFO -    Average Generations: 1.2\n",
      "2025-06-26 01:08:41,775 - INFO -    Average Confidence: 0.99\n",
      "2025-06-26 01:08:41,777 - INFO -    Average Quality: 0.99\n",
      "2025-06-26 01:08:41,777 - INFO - \n",
      "ğŸ“‹ Performance by Subject:\n",
      "2025-06-26 01:08:41,778 - INFO -    EM: 20/20 (100.0%)\n",
      "2025-06-26 01:08:41,778 - INFO -    CM: 13/13 (100.0%)\n",
      "2025-06-26 01:08:41,779 - INFO -    OPT: 5/5 (100.0%)\n",
      "2025-06-26 01:08:41,779 - INFO -    QMIT: 1/1 (100.0%)\n",
      "2025-06-26 01:08:41,780 - INFO -    AMONP: 7/7 (100.0%)\n",
      "2025-06-26 01:08:41,780 - INFO -    TSM: 4/4 (100.0%)\n",
      "2025-06-26 01:08:41,781 - INFO - \n",
      "ğŸ“ˆ Performance by Level:\n",
      "2025-06-26 01:08:41,781 - INFO -    Level 7: 38/38 (100.0%)\n",
      "2025-06-26 01:08:41,782 - INFO -    Level 8: 12/12 (100.0%)\n",
      "2025-06-26 01:08:41,782 - INFO - \n",
      "âœ… All results saved to: gemini_physics_results_o3_style.json\n",
      "2025-06-26 01:08:41,783 - INFO - ğŸ“ Detailed logs saved to: gemini_physics_solver.log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ‰ Completed! Processed 2000 problems\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    results = main_gemini_o3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.045857,
     "end_time": "2025-05-27T13:49:23.713585",
     "exception": false,
     "start_time": "2025-05-27T13:49:23.667728",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.046709,
     "end_time": "2025-05-27T13:49:23.806527",
     "exception": false,
     "start_time": "2025-05-27T13:49:23.759818",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 7445042,
     "sourceId": 11848870,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7524007,
     "sourceId": 11965383,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "icml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1853.896699,
   "end_time": "2025-05-27T13:49:24.677213",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-05-27T13:18:30.780514",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
